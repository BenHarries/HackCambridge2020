// Generated by dts-bundle v0.7.3

/**
    * Represents audio input configuration used for specifying what type of input to use (microphone, file, stream).
    * @class AudioConfig
    */
export abstract class AudioConfig {
        /**
            * Creates an AudioConfig object representing the default microphone on the system.
            * @member AudioConfig.fromDefaultMicrophoneInput
            * @function
            * @public
            * @returns {AudioConfig} The audio input configuration being created.
            */
        static fromDefaultMicrophoneInput(): AudioConfig;
        /**
            * Creates an AudioConfig object representing a microphone with the specified device ID.
            * @member AudioConfig.fromMicrophoneInput
            * @function
            * @public
            * @param {string | undefined} deviceId - Specifies the device ID of the microphone to be used.
            *        Default microphone is used the value is omitted.
            * @returns {AudioConfig} The audio input configuration being created.
            */
        static fromMicrophoneInput(deviceId?: string): AudioConfig;
        /**
            * Creates an AudioConfig object representing the specified file.
            * @member AudioConfig.fromWavFileInput
            * @function
            * @public
            * @param {File} fileName - Specifies the audio input file. Currently, only WAV / PCM with 16-bit
            *        samples, 16 kHz sample rate, and a single channel (Mono) is supported.
            * @returns {AudioConfig} The audio input configuration being created.
            */
        static fromWavFileInput(file: File): AudioConfig;
        /**
            * Creates an AudioConfig object representing the specified stream.
            * @member AudioConfig.fromStreamInput
            * @function
            * @public
            * @param {AudioInputStream | PullAudioInputStreamCallback} audioStream - Specifies the custom audio input
            *        stream. Currently, only WAV / PCM with 16-bit samples, 16 kHz sample rate, and a single channel
            *        (Mono) is supported.
            * @returns {AudioConfig} The audio input configuration being created.
            */
        static fromStreamInput(audioStream: AudioInputStream | PullAudioInputStreamCallback): AudioConfig;
        /**
            * Explicitly frees any external resource attached to the object
            * @member AudioConfig.prototype.close
            * @function
            * @public
            */
        abstract close(): void;
        /**
            * Sets an arbitrary property.
            * @member SpeechConfig.prototype.setProperty
            * @function
            * @public
            * @param {string} name - The name of the property to set.
            * @param {string} value - The new value of the property.
            */
        abstract setProperty(name: string, value: string): void;
        /**
            * Returns the current value of an arbitrary property.
            * @member SpeechConfig.prototype.getProperty
            * @function
            * @public
            * @param {string} name - The name of the property to query.
            * @param {string} def - The value to return in case the property is not known.
            * @returns {string} The current value, or provided default, of the given property.
            */
        abstract getProperty(name: string, def?: string): string;
}
/**
    * Represents audio input stream used for custom audio input configurations.
    * @private
    * @class AudioConfigImpl
    */
export class AudioConfigImpl extends AudioConfig implements IAudioSource {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {IAudioSource} source - An audio source.
            */
        constructor(source: IAudioSource);
        /**
            * Format information for the audio
            */
        readonly format: AudioStreamFormat;
        /**
            * @member AudioConfigImpl.prototype.close
            * @function
            * @public
            */
        close(): void;
        /**
            * @member AudioConfigImpl.prototype.id
            * @function
            * @public
            */
        id(): string;
        /**
            * @member AudioConfigImpl.prototype.turnOn
            * @function
            * @public
            * @returns {Promise<boolean>} A promise.
            */
        turnOn(): Promise<boolean>;
        /**
            * @member AudioConfigImpl.prototype.attach
            * @function
            * @public
            * @param {string} audioNodeId - The audio node id.
            * @returns {Promise<IAudioStreamNode>} A promise.
            */
        attach(audioNodeId: string): Promise<IAudioStreamNode>;
        /**
            * @member AudioConfigImpl.prototype.detach
            * @function
            * @public
            * @param {string} audioNodeId - The audio node id.
            */
        detach(audioNodeId: string): void;
        /**
            * @member AudioConfigImpl.prototype.turnOff
            * @function
            * @public
            * @returns {Promise<boolean>} A promise.
            */
        turnOff(): Promise<boolean>;
        /**
            * @member AudioConfigImpl.prototype.events
            * @function
            * @public
            * @returns {EventSource<AudioSourceEvent>} An event source for audio events.
            */
        readonly events: EventSource<AudioSourceEvent>;
        setProperty(name: string, value: string): void;
        getProperty(name: string, def?: string): string;
        readonly deviceInfo: Promise<ISpeechConfigAudioDevice>;
}

/**
    * Represents audio stream format used for custom audio input configurations.
    * @class AudioStreamFormat
    */
export abstract class AudioStreamFormat {
        /**
            * Creates an audio stream format object representing the default audio stream
            * format (16KHz 16bit mono PCM).
            * @member AudioStreamFormat.getDefaultInputFormat
            * @function
            * @public
            * @returns {AudioStreamFormat} The audio stream format being created.
            */
        static getDefaultInputFormat(): AudioStreamFormat;
        /**
            * Creates an audio stream format object with the specified pcm waveformat characteristics.
            * @member AudioStreamFormat.getWaveFormatPCM
            * @function
            * @public
            * @param {number} samplesPerSecond - Sample rate, in samples per second (Hertz).
            * @param {number} bitsPerSample - Bits per sample, typically 16.
            * @param {number} channels - Number of channels in the waveform-audio data. Monaural data
            *        uses one channel and stereo data uses two channels.
            * @returns {AudioStreamFormat} The audio stream format being created.
            */
        static getWaveFormatPCM(samplesPerSecond: number, bitsPerSample: number, channels: number): AudioStreamFormat;
        /**
            * Explicitly frees any external resource attached to the object
            * @member AudioStreamFormat.prototype.close
            * @function
            * @public
            */
        abstract close(): void;
}
/**
    * @private
    * @class AudioStreamFormatImpl
    */
export class AudioStreamFormatImpl extends AudioStreamFormat {
        /**
            * Creates an instance with the given values.
            * @constructor
            * @param {number} samplesPerSec - Samples per second.
            * @param {number} bitsPerSample - Bits per sample.
            * @param {number} channels - Number of channels.
            */
        constructor(samplesPerSec?: number, bitsPerSample?: number, channels?: number);
        /**
            * Retrieves the default input format.
            * @member AudioStreamFormatImpl.getDefaultInputFormat
            * @function
            * @public
            * @returns {AudioStreamFormatImpl} The default input format.
            */
        static getDefaultInputFormat(): AudioStreamFormatImpl;
        /**
            * Closes the configuration object.
            * @member AudioStreamFormatImpl.prototype.close
            * @function
            * @public
            */
        close(): void;
        /**
            * The format of the audio, valid values: 1 (PCM)
            * @member AudioStreamFormatImpl.prototype.formatTag
            * @function
            * @public
            */
        formatTag: number;
        /**
            * The number of channels, valid values: 1 (Mono).
            * @member AudioStreamFormatImpl.prototype.channels
            * @function
            * @public
            */
        channels: number;
        /**
            * The sample rate, valid values: 16000.
            * @member AudioStreamFormatImpl.prototype.samplesPerSec
            * @function
            * @public
            */
        samplesPerSec: number;
        /**
            * The bits per sample, valid values: 16
            * @member AudioStreamFormatImpl.prototype.b
            * @function
            * @public
            */
        bitsPerSample: number;
        /**
            * Average bytes per second, usually calculated as nSamplesPerSec * nChannels * ceil(wBitsPerSample, 8).
            * @member AudioStreamFormatImpl.prototype.avgBytesPerSec
            * @function
            * @public
            */
        avgBytesPerSec: number;
        /**
            * The size of a single frame, valid values: nChannels * ceil(wBitsPerSample, 8).
            * @member AudioStreamFormatImpl.prototype.blockAlign
            * @function
            * @public
            */
        blockAlign: number;
}

export const bufferSize: number;
/**
    * Represents audio input stream used for custom audio input configurations.
    * @class AudioInputStream
    */
export abstract class AudioInputStream {
        /**
            * Creates and initializes an instance.
            * @constructor
            */
        protected constructor();
        /**
            * Creates a memory backed PushAudioInputStream with the specified audio format.
            * @member AudioInputStream.createPushStream
            * @function
            * @public
            * @param {AudioStreamFormat} format - The audio data format in which audio will be
            *        written to the push audio stream's write() method (currently only support 16 kHz 16bit mono PCM).
            * @returns {PushAudioInputStream} The audio input stream being created.
            */
        static createPushStream(format?: AudioStreamFormat): PushAudioInputStream;
        /**
            * Creates a PullAudioInputStream that delegates to the specified callback interface for read()
            * and close() methods.
            * @member AudioInputStream.createPullStream
            * @function
            * @public
            * @param {PullAudioInputStreamCallback} callback - The custom audio input object, derived from
            *        PullAudioInputStreamCallback
            * @param {AudioStreamFormat} format - The audio data format in which audio will be returned from
            *        the callback's read() method (currently only support 16 kHz 16bit mono PCM).
            * @returns {PullAudioInputStream} The audio input stream being created.
            */
        static createPullStream(callback: PullAudioInputStreamCallback, format?: AudioStreamFormat): PullAudioInputStream;
        /**
            * Explicitly frees any external resource attached to the object
            * @member AudioInputStream.prototype.close
            * @function
            * @public
            */
        abstract close(): void;
}
/**
    * Represents memory backed push audio input stream used for custom audio input configurations.
    * @class PushAudioInputStream
    */
export abstract class PushAudioInputStream extends AudioInputStream {
        /**
            * Creates a memory backed PushAudioInputStream with the specified audio format.
            * @member PushAudioInputStream.create
            * @function
            * @public
            * @param {AudioStreamFormat} format - The audio data format in which audio will be written to the
            *        push audio stream's write() method (currently only support 16 kHz 16bit mono PCM).
            * @returns {PushAudioInputStream} The push audio input stream being created.
            */
        static create(format?: AudioStreamFormat): PushAudioInputStream;
        /**
            * Writes the audio data specified by making an internal copy of the data.
            * @member PushAudioInputStream.prototype.write
            * @function
            * @public
            * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
            */
        abstract write(dataBuffer: ArrayBuffer): void;
        /**
            * Closes the stream.
            * @member PushAudioInputStream.prototype.close
            * @function
            * @public
            */
        abstract close(): void;
}
/**
    * Represents memory backed push audio input stream used for custom audio input configurations.
    * @private
    * @class PushAudioInputStreamImpl
    */
export class PushAudioInputStreamImpl extends PushAudioInputStream implements IAudioSource {
        /**
            * Creates and initalizes an instance with the given values.
            * @constructor
            * @param {AudioStreamFormat} format - The audio stream format.
            */
        constructor(chunkSize: number, format?: AudioStreamFormat);
        /**
            * Format information for the audio
            */
        readonly format: AudioStreamFormat;
        /**
            * Writes the audio data specified by making an internal copy of the data.
            * @member PushAudioInputStreamImpl.prototype.write
            * @function
            * @public
            * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
            */
        write(dataBuffer: ArrayBuffer): void;
        /**
            * Closes the stream.
            * @member PushAudioInputStreamImpl.prototype.close
            * @function
            * @public
            */
        close(): void;
        id(): string;
        turnOn(): Promise<boolean>;
        attach(audioNodeId: string): Promise<IAudioStreamNode>;
        detach(audioNodeId: string): void;
        turnOff(): Promise<boolean>;
        readonly events: EventSource<AudioSourceEvent>;
        readonly deviceInfo: Promise<ISpeechConfigAudioDevice>;
}
export abstract class PullAudioInputStream extends AudioInputStream {
        /**
            * Creates and initializes and instance.
            * @constructor
            */
        protected constructor();
        /**
            * Creates a PullAudioInputStream that delegates to the specified callback interface for
            * read() and close() methods, using the default format (16 kHz 16bit mono PCM).
            * @member PullAudioInputStream.create
            * @function
            * @public
            * @param {PullAudioInputStreamCallback} callback - The custom audio input object,
            *        derived from PullAudioInputStreamCustomCallback
            * @param {AudioStreamFormat} format - The audio data format in which audio will be
            *        returned from the callback's read() method (currently only support 16 kHz 16bit mono PCM).
            * @returns {PullAudioInputStream} The push audio input stream being created.
            */
        static create(callback: PullAudioInputStreamCallback, format?: AudioStreamFormat): PullAudioInputStream;
        /**
            * Explicitly frees any external resource attached to the object
            * @member PullAudioInputStream.prototype.close
            * @function
            * @public
            */
        abstract close(): void;
}
/**
    * Represents audio input stream used for custom audio input configurations.
    * @private
    * @class PullAudioInputStreamImpl
    */
export class PullAudioInputStreamImpl extends PullAudioInputStream implements IAudioSource {
        /**
            * Creates a PullAudioInputStream that delegates to the specified callback interface for
            * read() and close() methods, using the default format (16 kHz 16bit mono PCM).
            * @constructor
            * @param {PullAudioInputStreamCallback} callback - The custom audio input object,
            *        derived from PullAudioInputStreamCustomCallback
            * @param {AudioStreamFormat} format - The audio data format in which audio will be
            *        returned from the callback's read() method (currently only support 16 kHz 16bit mono PCM).
            */
        constructor(callback: PullAudioInputStreamCallback, format?: AudioStreamFormatImpl);
        /**
            * Format information for the audio
            */
        readonly format: AudioStreamFormat;
        /**
            * Closes the stream.
            * @member PullAudioInputStreamImpl.prototype.close
            * @function
            * @public
            */
        close(): void;
        id(): string;
        turnOn(): Promise<boolean>;
        attach(audioNodeId: string): Promise<IAudioStreamNode>;
        detach(audioNodeId: string): void;
        turnOff(): Promise<boolean>;
        readonly events: EventSource<AudioSourceEvent>;
        readonly deviceInfo: Promise<ISpeechConfigAudioDevice>;
}

export const bufferSize: number;
/**
    * Represents audio input stream used for custom audio input configurations.
    * @class AudioInputStream
    */
export abstract class AudioOutputStream {
        /**
            * Creates and initializes an instance.
            * @constructor
            */
        protected constructor();
        /**
            * Creates a memory backed PullAudioOutputStream with the specified audio format.
            * @member AudioInputStream.createPullStream
            * @function
            * @public
            * @param {AudioStreamFormat} format - The audio data format in which audio will be
            *        written to the push audio stream's write() method (currently only support 16 kHz 16bit mono PCM).
            * @returns {PullAudioOutputStream} The audio input stream being created.
            */
        static createPullStream(format?: AudioStreamFormat): PullAudioOutputStream;
        /**
            * Explicitly frees any external resource attached to the object
            * @member AudioInputStream.prototype.close
            * @function
            * @public
            */
        abstract close(): void;
}
/**
    * Represents memory backed push audio input stream used for custom audio input configurations.
    * @class PullAudioOutputStream
    */
export abstract class PullAudioOutputStream extends AudioOutputStream {
        /**
            * Creates a memory backed PullAudioOutputStream with the specified audio format.
            * @member PullAudioOutputStream.create
            * @function
            * @public
            * @param {AudioStreamFormat} format - The audio data format in which audio will be written to the
            *        push audio stream's write() method (currently only support 16 kHz 16bit mono PCM).
            * @returns {PullAudioOutputStream} The push audio input stream being created.
            */
        static create(format?: AudioStreamFormat): PullAudioOutputStream;
        /**
            * Reads audio data from the internal buffer.
            * @member PullAudioOutputStream.prototype.read
            * @function
            * @public
            * @returns {Promise<ArrayBuffer>} Audio buffer data.
            */
        abstract read(): Promise<ArrayBuffer>;
        /**
            * Closes the stream.
            * @member PullAudioOutputStream.prototype.close
            * @function
            * @public
            */
        abstract close(): void;
}
/**
    * Represents memory backed push audio input stream used for custom audio input configurations.
    * @private
    * @class PullAudioOutputStreamImpl
    */
export class PullAudioOutputStreamImpl extends PullAudioOutputStream {
        /**
            * Creates and initalizes an instance with the given values.
            * @constructor
            * @param {AudioStreamFormat} format - The audio stream format.
            */
        constructor(chunkSize: number, format?: AudioStreamFormat);
        /**
            * Format information for the audio
            */
        readonly format: AudioStreamFormat;
        /**
            * Checks if the stream is closed
            * @member PullAudioOutputStreamImpl.prototype.isClosed
            * @property
            * @public
            */
        readonly isClosed: boolean;
        /**
            * Gets the id of the stream
            * @member PullAudioOutputStreamImpl.prototype.id
            * @property
            * @public
            */
        readonly id: string;
        /**
            * Reads data from the buffer
            * @member PullAudioOutputStreamImpl.prototype.read
            * @function
            * @public
            * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
            */
        read(): Promise<ArrayBuffer>;
        /**
            * Writes the audio data specified by making an internal copy of the data.
            * @member PullAudioOutputStreamImpl.prototype.write
            * @function
            * @public
            * @param {ArrayBuffer} dataBuffer - The audio buffer of which this function will make a copy.
            */
        write(dataBuffer: ArrayBuffer): void;
        /**
            * Closes the stream.
            * @member PullAudioOutputStreamImpl.prototype.close
            * @function
            * @public
            */
        close(): void;
}

/**
    * Defines the possible reasons a recognition result might be canceled.
    * @class CancellationReason
    */
export enum CancellationReason {
        /**
            * Indicates that an error occurred during speech recognition.
            * @member CancellationReason.Error
            */
        Error = 0,
        /**
            * Indicates that the end of the audio stream was reached.
            * @member CancellationReason.EndOfStream
            */
        EndOfStream = 1
}

/**
    * An abstract base class that defines callback methods (read() and close()) for
    * custom audio input streams).
    * @class PullAudioInputStreamCallback
    */
export abstract class PullAudioInputStreamCallback {
        /**
            * Reads data from audio input stream into the data buffer. The maximal number of bytes
            * to be read is determined by the size of dataBuffer.
            * @member PullAudioInputStreamCallback.prototype.read
            * @function
            * @public
            * @param {ArrayBuffer} dataBuffer - The byte array to store the read data.
            * @returns {number} the number of bytes have been read.
            */
        abstract read(dataBuffer: ArrayBuffer): number;
        /**
            * Closes the audio input stream.
            * @member PullAudioInputStreamCallback.prototype.close
            * @function
            * @public
            */
        abstract close(): void;
}

/**
    * Represents a keyword recognition model for recognizing when
    * the user says a keyword to initiate further speech recognition.
    * @class KeywordRecognitionModel
    */
export class KeywordRecognitionModel {
        /**
            * Creates a keyword recognition model using the specified filename.
            * @member KeywordRecognitionModel.fromFile
            * @function
            * @public
            * @param {string} fileName - A string that represents file name for the keyword recognition model.
            *        Note, the file can point to a zip file in which case the model
            *        will be extracted from the zip.
            * @returns {KeywordRecognitionModel} The keyword recognition model being created.
            */
        static fromFile(fileName: string): KeywordRecognitionModel;
        /**
            * Creates a keyword recognition model using the specified filename.
            * @member KeywordRecognitionModel.fromStream
            * @function
            * @public
            * @param {string} file - A File that represents file for the keyword recognition model.
            *        Note, the file can point to a zip file in which case the model will be extracted from the zip.
            * @returns {KeywordRecognitionModel} The keyword recognition model being created.
            */
        static fromStream(file: File): KeywordRecognitionModel;
        /**
            * Dispose of associated resources.
            * @member KeywordRecognitionModel.prototype.close
            * @function
            * @public
            */
        close(): void;
}

/**
    * Defines content for session events like SessionStarted/Stopped, SoundStarted/Stopped.
    * @class SessionEventArgs
    */
export class SessionEventArgs {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {string} sessionId - The session id.
            */
        constructor(sessionId: string);
        /**
            * Represents the session identifier.
            * @member SessionEventArgs.prototype.sessionId
            * @function
            * @public
            * @returns {string} Represents the session identifier.
            */
        readonly sessionId: string;
}

/**
    * Defines payload for session events like Speech Start/End Detected
    * @class
    */
export class RecognitionEventArgs extends SessionEventArgs {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {number} offset - The offset.
            * @param {string} sessionId - The session id.
            */
        constructor(offset: number, sessionId?: string);
        /**
            * Represents the message offset
            * @member RecognitionEventArgs.prototype.offset
            * @function
            * @public
            */
        readonly offset: number;
}

/**
    * Define Speech Recognizer output formats.
    * @class OutputFormat
    */
export enum OutputFormat {
        /**
            * @member OutputFormat.Simple
            */
        Simple = 0,
        /**
            * @member OutputFormat.Detailed
            */
        Detailed = 1
}

/**
    * Intent recognition result event arguments.
    * @class
    */
export class IntentRecognitionEventArgs extends RecognitionEventArgs {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param result - The result of the intent recognition.
            * @param offset - The offset.
            * @param sessionId - The session id.
            */
        constructor(result: IntentRecognitionResult, offset?: number, sessionId?: string);
        /**
            * Represents the intent recognition result.
            * @member IntentRecognitionEventArgs.prototype.result
            * @function
            * @public
            * @returns {IntentRecognitionResult} Represents the intent recognition result.
            */
        readonly result: IntentRecognitionResult;
}

/**
    * Defines result of speech recognition.
    * @class RecognitionResult
    */
export class RecognitionResult {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {string} resultId - The result id.
            * @param {ResultReason} reason - The reason.
            * @param {string} text - The recognized text.
            * @param {number} duration - The duration.
            * @param {number} offset - The offset into the stream.
            * @param {string} errorDetails - Error details, if provided.
            * @param {string} json - Additional Json, if provided.
            * @param {PropertyCollection} properties - Additional properties, if provided.
            */
        constructor(resultId?: string, reason?: ResultReason, text?: string, duration?: number, offset?: number, errorDetails?: string, json?: string, properties?: PropertyCollection);
        /**
            * Specifies the result identifier.
            * @member RecognitionResult.prototype.resultId
            * @function
            * @public
            * @returns {string} Specifies the result identifier.
            */
        readonly resultId: string;
        /**
            * Specifies status of the result.
            * @member RecognitionResult.prototype.reason
            * @function
            * @public
            * @returns {ResultReason} Specifies status of the result.
            */
        readonly reason: ResultReason;
        /**
            * Presents the recognized text in the result.
            * @member RecognitionResult.prototype.text
            * @function
            * @public
            * @returns {string} Presents the recognized text in the result.
            */
        readonly text: string;
        /**
            * Duration of recognized speech in 100 nano second incements.
            * @member RecognitionResult.prototype.duration
            * @function
            * @public
            * @returns {number} Duration of recognized speech in 100 nano second incements.
            */
        readonly duration: number;
        /**
            * Offset of recognized speech in 100 nano second incements.
            * @member RecognitionResult.prototype.offset
            * @function
            * @public
            * @returns {number} Offset of recognized speech in 100 nano second incements.
            */
        readonly offset: number;
        /**
            * In case of an unsuccessful recognition, provides details of the occurred error.
            * @member RecognitionResult.prototype.errorDetails
            * @function
            * @public
            * @returns {string} a brief description of an error.
            */
        readonly errorDetails: string;
        /**
            * A string containing Json serialized recognition result as it was received from the service.
            * @member RecognitionResult.prototype.json
            * @function
            * @private
            * @returns {string} Json serialized representation of the result.
            */
        readonly json: string;
        /**
            *  The set of properties exposed in the result.
            * @member RecognitionResult.prototype.properties
            * @function
            * @public
            * @returns {PropertyCollection} The set of properties exposed in the result.
            */
        readonly properties: PropertyCollection;
}

/**
    * Defines result of speech recognition.
    * @class SpeechRecognitionResult
    */
export class SpeechRecognitionResult extends RecognitionResult {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @public
            * @param {string} resultId - The result id.
            * @param {ResultReason} reason - The reason.
            * @param {string} text - The recognized text.
            * @param {number} duration - The duration.
            * @param {number} offset - The offset into the stream.
            * @param {string} errorDetails - Error details, if provided.
            * @param {string} json - Additional Json, if provided.
            * @param {PropertyCollection} properties - Additional properties, if provided.
            */
        constructor(resultId?: string, reason?: ResultReason, text?: string, duration?: number, offset?: number, errorDetails?: string, json?: string, properties?: PropertyCollection);
}

/**
    * Intent recognition result.
    * @class
    */
export class IntentRecognitionResult extends SpeechRecognitionResult {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param intentId - The intent id.
            * @param resultId - The result id.
            * @param reason - The reason.
            * @param text - The recognized text.
            * @param duration - The duration.
            * @param offset - The offset into the stream.
            * @param errorDetails - Error details, if provided.
            * @param json - Additional Json, if provided.
            * @param properties - Additional properties, if provided.
            */
        constructor(intentId?: string, resultId?: string, reason?: ResultReason, text?: string, duration?: number, offset?: number, errorDetails?: string, json?: string, properties?: PropertyCollection);
        /**
            * A String that represents the intent identifier being recognized.
            * @member IntentRecognitionResult.prototype.intentId
            * @function
            * @public
            * @returns {string} A String that represents the intent identifier being recognized.
            */
        readonly intentId: string;
}

/**
    * Language understanding model
    * @class LanguageUnderstandingModel
    */
export class LanguageUnderstandingModel {
        /**
            * Creates and initializes a new instance
            * @constructor
            */
        protected constructor();
        /**
            * Creates an language understanding model using the specified endpoint.
            * @member LanguageUnderstandingModel.fromEndpoint
            * @function
            * @public
            * @param {URL} uri - A String that represents the endpoint of the language understanding model.
            * @returns {LanguageUnderstandingModel} The language understanding model being created.
            */
        static fromEndpoint(uri: URL): LanguageUnderstandingModel;
        /**
            * Creates an language understanding model using the application id of Language Understanding service.
            * @member LanguageUnderstandingModel.fromAppId
            * @function
            * @public
            * @param {string} appId - A String that represents the application id of Language Understanding service.
            * @returns {LanguageUnderstandingModel} The language understanding model being created.
            */
        static fromAppId(appId: string): LanguageUnderstandingModel;
        /**
            * Creates a language understanding model using hostname, subscription key and application
            * id of Language Understanding service.
            * @member LanguageUnderstandingModel.fromSubscription
            * @function
            * @public
            * @param {string} subscriptionKey - A String that represents the subscription key of
            *        Language Understanding service.
            * @param {string} appId - A String that represents the application id of Language
            *        Understanding service.
            * @param {LanguageUnderstandingModel} region - A String that represents the region
            *        of the Language Understanding service (see the <a href="https://aka.ms/csspeech/region">region page</a>).
            * @returns {LanguageUnderstandingModel} The language understanding model being created.
            */
        static fromSubscription(subscriptionKey: string, appId: string, region: string): LanguageUnderstandingModel;
}
/**
    * @private
    * @class LanguageUnderstandingModelImpl
    */
export class LanguageUnderstandingModelImpl extends LanguageUnderstandingModel {
        appId: string;
        region: string;
        subscriptionKey: string;
}

/**
    * Defines contents of speech recognizing/recognized event.
    * @class SpeechRecognitionEventArgs
    */
export class SpeechRecognitionEventArgs extends RecognitionEventArgs {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {SpeechRecognitionResult} result - The speech recognition result.
            * @param {number} offset - The offset.
            * @param {string} sessionId - The session id.
            */
        constructor(result: SpeechRecognitionResult, offset?: number, sessionId?: string);
        /**
            * Specifies the recognition result.
            * @member SpeechRecognitionEventArgs.prototype.result
            * @function
            * @public
            * @returns {SpeechRecognitionResult} the recognition result.
            */
        readonly result: SpeechRecognitionResult;
}

/**
    * Defines content of a RecognitionErrorEvent.
    * @class SpeechRecognitionCanceledEventArgs
    */
export class SpeechRecognitionCanceledEventArgs extends RecognitionEventArgs {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {CancellationReason} reason - The cancellation reason.
            * @param {string} errorDetails - Error details, if provided.
            * @param {number} offset - The offset.
            * @param {string} sessionId - The session id.
            */
        constructor(reason: CancellationReason, errorDetails: string, errorCode: CancellationErrorCode, offset?: number, sessionId?: string);
        /**
            * The reason the recognition was canceled.
            * @member SpeechRecognitionCanceledEventArgs.prototype.reason
            * @function
            * @public
            * @returns {CancellationReason} Specifies the reason canceled.
            */
        readonly reason: CancellationReason;
        /**
            * The error code in case of an unsuccessful recognition.
            * Added in version 1.1.0.
            * @return An error code that represents the error reason.
            */
        readonly errorCode: CancellationErrorCode;
        /**
            * In case of an unsuccessful recognition, provides details of the occurred error.
            * @member SpeechRecognitionCanceledEventArgs.prototype.errorDetails
            * @function
            * @public
            * @returns {string} A String that represents the error details.
            */
        readonly errorDetails: string;
}

/**
    * Translation text result event arguments.
    * @class TranslationRecognitionEventArgs
    */
export class TranslationRecognitionEventArgs extends RecognitionEventArgs {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {TranslationRecognitionResult} result - The translation recognition result.
            * @param {number} offset - The offset.
            * @param {string} sessionId - The session id.
            */
        constructor(result: TranslationRecognitionResult, offset?: number, sessionId?: string);
        /**
            * Specifies the recognition result.
            * @member TranslationRecognitionEventArgs.prototype.result
            * @function
            * @public
            * @returns {TranslationRecognitionResult} the recognition result.
            */
        readonly result: TranslationRecognitionResult;
}

/**
    * Translation Synthesis event arguments
    * @class TranslationSynthesisEventArgs
    */
export class TranslationSynthesisEventArgs extends SessionEventArgs {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {TranslationSynthesisResult} result - The translation synthesis result.
            * @param {string} sessionId - The session id.
            */
        constructor(result: TranslationSynthesisResult, sessionId?: string);
        /**
            * Specifies the translation synthesis result.
            * @member TranslationSynthesisEventArgs.prototype.result
            * @function
            * @public
            * @returns {TranslationSynthesisResult} Specifies the translation synthesis result.
            */
        readonly result: TranslationSynthesisResult;
}

/**
    * Translation text result.
    * @class TranslationRecognitionResult
    */
export class TranslationRecognitionResult extends SpeechRecognitionResult {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {Translations} translations - The translations.
            * @param {string} resultId - The result id.
            * @param {ResultReason} reason - The reason.
            * @param {string} text - The recognized text.
            * @param {number} duration - The duration.
            * @param {number} offset - The offset into the stream.
            * @param {string} errorDetails - Error details, if provided.
            * @param {string} json - Additional Json, if provided.
            * @param {PropertyCollection} properties - Additional properties, if provided.
            */
        constructor(translations: Translations, resultId?: string, reason?: ResultReason, text?: string, duration?: number, offset?: number, errorDetails?: string, json?: string, properties?: PropertyCollection);
        /**
            * Presents the translation results. Each item in the dictionary represents
            * a translation result in one of target languages, where the key is the name
            * of the target language, in BCP-47 format, and the value is the translation
            * text in the specified language.
            * @member TranslationRecognitionResult.prototype.translations
            * @function
            * @public
            * @returns {Translations} the current translation map that holds all translations requested.
            */
        readonly translations: Translations;
}

/**
    * Defines translation synthesis result, i.e. the voice output of the translated
    * text in the target language.
    * @class TranslationSynthesisResult
    */
export class TranslationSynthesisResult {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {ResultReason} reason - The synthesis reason.
            * @param {ArrayBuffer} audio - The audio data.
            */
        constructor(reason: ResultReason, audio: ArrayBuffer);
        /**
            * Translated text in the target language.
            * @member TranslationSynthesisResult.prototype.audio
            * @function
            * @public
            * @returns {ArrayBuffer} Translated audio in the target language.
            */
        readonly audio: ArrayBuffer;
        /**
            * The synthesis status.
            * @member TranslationSynthesisResult.prototype.reason
            * @function
            * @public
            * @returns {ResultReason} The synthesis status.
            */
        readonly reason: ResultReason;
}

/**
    * Defines the possible reasons a recognition result might be generated.
    * @class ResultReason
    */
export enum ResultReason {
        /**
            * Indicates speech could not be recognized. More details
            * can be found in the NoMatchDetails object.
            * @member ResultReason.NoMatch
            */
        NoMatch = 0,
        /**
            * Indicates that the recognition was canceled. More details
            * can be found using the CancellationDetails object.
            * @member ResultReason.Canceled
            */
        Canceled = 1,
        /**
            * Indicates the speech result contains hypothesis text.
            * @member ResultReason.RecognizedSpeech
            */
        RecognizingSpeech = 2,
        /**
            * Indicates the speech result contains final text that has been recognized.
            * Speech Recognition is now complete for this phrase.
            * @member ResultReason.RecognizedSpeech
            */
        RecognizedSpeech = 3,
        /**
            * Indicates the intent result contains hypothesis text and intent.
            * @member ResultReason.RecognizingIntent
            */
        RecognizingIntent = 4,
        /**
            * Indicates the intent result contains final text and intent.
            * Speech Recognition and Intent determination are now complete for this phrase.
            * @member ResultReason.RecognizedIntent
            */
        RecognizedIntent = 5,
        /**
            * Indicates the translation result contains hypothesis text and its translation(s).
            * @member ResultReason.TranslatingSpeech
            */
        TranslatingSpeech = 6,
        /**
            * Indicates the translation result contains final text and corresponding translation(s).
            * Speech Recognition and Translation are now complete for this phrase.
            * @member ResultReason.TranslatedSpeech
            */
        TranslatedSpeech = 7,
        /**
            * Indicates the synthesized audio result contains a non-zero amount of audio data
            * @member ResultReason.SynthesizingAudio
            */
        SynthesizingAudio = 8,
        /**
            * Indicates the synthesized audio is now complete for this phrase.
            * @member ResultReason.SynthesizingAudioCompleted
            */
        SynthesizingAudioCompleted = 9
}

/**
    * Speech configuration.
    * @class SpeechConfig
    */
export abstract class SpeechConfig {
        /**
            * Creates and initializes an instance.
            * @constructor
            */
        protected constructor();
        /**
            * Static instance of SpeechConfig returned by passing subscriptionKey and service region.
            * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.
            * @member SpeechConfig.fromSubscription
            * @function
            * @public
            * @param {string} subscriptionKey - The subscription key.
            * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
            * @returns {SpeechConfig} The speech factory
            */
        static fromSubscription(subscriptionKey: string, region: string): SpeechConfig;
        /**
            * Creates an instance of the speech config with specified endpoint and subscription key.
            * This method is intended only for users who use a non-standard service endpoint or parameters.
            * Note: Please use your LanguageUnderstanding subscription key in case you want to use the Intent recognizer.
            * Note: The query parameters specified in the endpoint URL are not changed, even if they are set by any other APIs.
            * For example, if language is defined in the uri as query parameter "language=de-DE", and also set by
            *              SpeechConfig.speechRecognitionLanguage = "en-US", the language setting in uri takes precedence,
            *              and the effective language is "de-DE". Only the parameters that are not specified in the
            *              endpoint URL can be set by other APIs.
            * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
            *       fromEndpoint method, and then set authorizationToken="token" on the created SpeechConfig instance to
            *       use the authorization token.
            * @member SpeechConfig.fromEndpoint
            * @function
            * @public
            * @param {URL} endpoint - The service endpoint to connect to.
            * @param {string} subscriptionKey - The subscription key. If a subscription key is not specified, an authorization token must be set.
            * @returns {SpeechConfig} A speech factory instance.
            */
        static fromEndpoint(endpoint: URL, subscriptionKey?: string): SpeechConfig;
        /**
            * Creates an instance of the speech factory with specified initial authorization token and region.
            * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            *       expires, the caller needs to refresh it by calling this setter with a new valid token.
            * Note: Please use a token derived from your LanguageUnderstanding subscription key in case you want
            *       to use the Intent recognizer. As configuration values are copied when creating a new recognizer,
            *       the new token value will not apply to recognizers that have already been created. For recognizers
            *       that have been created before, you need to set authorization token of the corresponding recognizer
            *       to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
            * @member SpeechConfig.fromAuthorizationToken
            * @function
            * @public
            * @param {string} authorizationToken - The initial authorization token.
            * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
            * @returns {SpeechConfig} A speech factory instance.
            */
        static fromAuthorizationToken(authorizationToken: string, region: string): SpeechConfig;
        /**
            * Sets the proxy configuration.
            * Only relevant in Node.js environments.
            * Added in version 1.4.0.
            * @param proxyHostName The host name of the proxy server.
            * @param proxyPort The port number of the proxy server.
            */
        abstract setProxy(proxyHostName: string, proxyPort: number): void;
        /**
            * Sets the proxy configuration.
            * Only relevant in Node.js environments.
            * Added in version 1.4.0.
            * @param proxyHostName The host name of the proxy server, without the protocol scheme (http://)
            * @param porxyPort The port number of the proxy server.
            * @param proxyUserName The user name of the proxy server.
            * @param proxyPassword The password of the proxy server.
            */
        abstract setProxy(proxyHostName: string, proxyPort: number, proxyUserName: string, proxyPassword: string): void;
        /**
         * Gets/Sets the authorization token.
         * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
         * expires, the caller needs to refresh it by calling this setter with a new valid token.
         * @member SpeechConfig.prototype.authorizationToken
         * @function
         * @public
         * @param {string} value - The authorization token.
         */
        abstract authorizationToken: string;
        /**
         * Gets/Sets the input language.
         * @member SpeechConfig.prototype.speechRecognitionLanguage
         * @function
         * @public
         * @param {string} value - The authorization token.
         */
        abstract speechRecognitionLanguage: string;
        /**
            * Sets an arbitrary property.
            * @member SpeechConfig.prototype.setProperty
            * @function
            * @public
            * @param {string} name - The name of the property to set.
            * @param {string} value - The new value of the property.
            */
        abstract setProperty(name: string, value: string): void;
        /**
            * Returns the current value of an arbitrary property.
            * @member SpeechConfig.prototype.getProperty
            * @function
            * @public
            * @param {string} name - The name of the property to query.
            * @param {string} def - The value to return in case the property is not known.
            * @returns {string} The current value, or provided default, of the given property.
            */
        abstract getProperty(name: string, def?: string): string;
        /**
         * Gets/Sets the output format.
         * @member SpeechConfig.prototype.outputFormat
         * @function
         * @public
         */
        abstract outputFormat: OutputFormat;
        /**
         * Gets/Sets the endpoint ID of a customized speech model that is used for speech recognition.
         * @member SpeechConfig.prototype.endpointId
         * @function
         * @public
         * @param {string} value - The endpoint ID
         */
        abstract endpointId: string;
        /**
            * Closes the configuration.
            * @member SpeechConfig.prototype.close
            * @function
            * @public
            */
        close(): void;
        /**
            * @member SpeechConfig.prototype.subscriptionKey
            * @function
            * @public
            * @return {SubscriptionKey} The subscription key set on the config.
            */
        abstract readonly subscriptionKey: string;
        /**
            * @member SpeechConfig.prototype.region
            * @function
            * @public
            * @return {region} The region set on the config.
            */
        abstract readonly region: string;
        /**
            * @member SpeechConfig.prototype.setServiceProperty
            * @function
            * @public
            * @param {name} The name of the property.
            * @param {value} Value to set.
            * @param {channel} The channel used to pass the specified property to service.
            * @summary Sets a property value that will be passed to service using the specified channel.
            * Added in version 1.7.0.
            */
        abstract setServiceProperty(name: string, value: string, channel: ServicePropertyChannel): void;
        /**
            * @member SpeechConfig.prototype.setProfanity
            * @function
            * @public
            * @param {profanity} Profanity option to set.
            * @summary Sets profanity option.
            * Added in version 1.7.0.
            */
        abstract setProfanity(profanity: ProfanityOption): void;
        /**
            * @member SpeechConfig.prototype.enableAudioLogging
            * @function
            * @public
            * @summary Enable audio logging in service.
            * Added in version 1.7.0.
            */
        abstract enableAudioLogging(): void;
        /**
            * @member SpeechConfig.prototype.requestWordLevelTimestamps
            * @function
            * @public
            * @summary Includes word-level timestamps.
            * Added in version 1.7.0.
            */
        abstract requestWordLevelTimestamps(): void;
        /**
            * @member SpeechConfig.prototype.enableDictation
            * @function
            * @public
            * @summary Enable dictation. Only supported in speech continuous recognition.
            * Added in version 1.7.0.
            */
        abstract enableDictation(): void;
}
/**
    * @public
    * @class SpeechConfigImpl
    */
export class SpeechConfigImpl extends SpeechConfig {
        constructor();
        readonly properties: PropertyCollection;
        readonly endPoint: URL;
        readonly subscriptionKey: string;
        readonly region: string;
        authorizationToken: string;
        speechRecognitionLanguage: string;
        outputFormat: OutputFormat;
        endpointId: string;
        setProperty(name: string | PropertyId, value: string): void;
        getProperty(name: string | PropertyId, def?: string): string;
        setProxy(proxyHostName: string, proxyPort: number): void;
        setProxy(proxyHostName: string, proxyPort: number, proxyUserName: string, proxyPassword: string): void;
        setServiceProperty(name: string, value: string, channel: ServicePropertyChannel): void;
        setProfanity(profanity: ProfanityOption): void;
        enableAudioLogging(): void;
        requestWordLevelTimestamps(): void;
        enableDictation(): void;
        clone(): SpeechConfigImpl;
}

/**
    * Speech translation configuration.
    * @class SpeechTranslationConfig
    */
export abstract class SpeechTranslationConfig extends SpeechConfig {
        /**
            * Creates an instance of recognizer config.
            */
        protected constructor();
        /**
            * Static instance of SpeechTranslationConfig returned by passing a subscription key and service region.
            * @member SpeechTranslationConfig.fromSubscription
            * @function
            * @public
            * @param {string} subscriptionKey - The subscription key.
            * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
            * @returns {SpeechTranslationConfig} The speech translation config.
            */
        static fromSubscription(subscriptionKey: string, region: string): SpeechTranslationConfig;
        /**
            * Static instance of SpeechTranslationConfig returned by passing authorization token and service region.
            * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            *       expires, the caller needs to refresh it by setting the property authorizationToken with a new
            *       valid token. Otherwise, all the recognizers created by this SpeechTranslationConfig instance
            *       will encounter errors during recognition.
            * As configuration values are copied when creating a new recognizer, the new token value will not apply
            * to recognizers that have already been created.
            * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
            * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
            * @member SpeechTranslationConfig.fromAuthorizationToken
            * @function
            * @public
            * @param {string} authorizationToken - The authorization token.
            * @param {string} region - The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
            * @returns {SpeechTranslationConfig} The speech translation config.
            */
        static fromAuthorizationToken(authorizationToken: string, region: string): SpeechTranslationConfig;
        /**
            * Creates an instance of the speech translation config with specified endpoint and subscription key.
            * This method is intended only for users who use a non-standard service endpoint or paramters.
            * Note: The query properties specified in the endpoint URL are not changed, even if they are
            *       set by any other APIs. For example, if language is defined in the uri as query parameter
            *       "language=de-DE", and also set by the speechRecognitionLanguage property, the language
            *       setting in uri takes precedence, and the effective language is "de-DE".
            * Only the properties that are not specified in the endpoint URL can be set by other APIs.
            * Note: To use authorization token with fromEndpoint, pass an empty string to the subscriptionKey in the
            *       fromEndpoint method, and then set authorizationToken="token" on the created SpeechConfig instance to
            *       use the authorization token.
            * @member SpeechTranslationConfig.fromEndpoint
            * @function
            * @public
            * @param {URL} endpoint - The service endpoint to connect to.
            * @param {string} subscriptionKey - The subscription key.
            * @returns {SpeechTranslationConfig} A speech config instance.
            */
        static fromEndpoint(endpoint: URL, subscriptionKey: string): SpeechTranslationConfig;
        /**
            * Gets/Sets the authorization token.
            * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            * expires, the caller needs to refresh it by calling this setter with a new valid token.
            * @member SpeechTranslationConfig.prototype.authorizationToken
            * @function
            * @public
            * @param {string} value - The authorization token.
            */
        abstract authorizationToken: string;
        /**
            * Gets/Sets the speech recognition language.
            * @member SpeechTranslationConfig.prototype.speechRecognitionLanguage
            * @function
            * @public
            * @param {string} value - The authorization token.
            */
        abstract speechRecognitionLanguage: string;
        /**
            * Add a (text) target language to translate into.
            * @member SpeechTranslationConfig.prototype.addTargetLanguage
            * @function
            * @public
            * @param {string} value - The language such as de-DE
            */
        abstract addTargetLanguage(value: string): void;
        /**
            * Gets the (text) target language to translate into.
            * @member SpeechTranslationConfig.prototype.targetLanguages
            * @function
            * @public
            * @param {string} value - The language such as de-DE
            */
        abstract readonly targetLanguages: string[];
        /**
         * Gets/Sets voice of the translated language, enable voice synthesis output.
         * @member SpeechTranslationConfig.prototype.voiceName
         * @function
         * @public
         * @param {string} value - The name of the voice.
         */
        abstract voiceName: string;
        /**
            * Sets a named property as value
            * @member SpeechTranslationConfig.prototype.setProperty
            * @function
            * @public
            * @param {string} name - The name of the property.
            * @param {string} value - The value.
            */
        abstract setProperty(name: string, value: string): void;
        /**
            * Dispose of associated resources.
            * @member SpeechTranslationConfig.prototype.close
            * @function
            * @public
            */
        abstract close(): void;
}
/**
    * @private
    * @class SpeechTranslationConfigImpl
    */
export class SpeechTranslationConfigImpl extends SpeechTranslationConfig {
        constructor();
        /**
            * Gets/Sets the authorization token.
            * If this is set, subscription key is ignored.
            * User needs to make sure the provided authorization token is valid and not expired.
            * @member SpeechTranslationConfigImpl.prototype.authorizationToken
            * @function
            * @public
            * @param {string} value - The authorization token.
            */
        authorizationToken: string;
        /**
            * Gets/Sets the speech recognition language.
            * @member SpeechTranslationConfigImpl.prototype.speechRecognitionLanguage
            * @function
            * @public
            * @param {string} value - The authorization token.
            */
        speechRecognitionLanguage: string;
        /**
            * @member SpeechTranslationConfigImpl.prototype.subscriptionKey
            * @function
            * @public
            */
        readonly subscriptionKey: string;
        /**
         * Gets/Sets the output format
         * @member SpeechTranslationConfigImpl.prototype.outputFormat
         * @function
         * @public
         */
        outputFormat: OutputFormat;
        /**
         * Gets/Sets the endpoint id.
         * @member SpeechTranslationConfigImpl.prototype.endpointId
         * @function
         * @public
         */
        endpointId: string;
        /**
            * Add a (text) target language to translate into.
            * @member SpeechTranslationConfigImpl.prototype.addTargetLanguage
            * @function
            * @public
            * @param {string} value - The language such as de-DE
            */
        addTargetLanguage(value: string): void;
        /**
            * Gets the (text) target language to translate into.
            * @member SpeechTranslationConfigImpl.prototype.targetLanguages
            * @function
            * @public
            * @param {string} value - The language such as de-DE
            */
        readonly targetLanguages: string[];
        /**
         * Gets/Sets the voice of the translated language, enable voice synthesis output.
         * @member SpeechTranslationConfigImpl.prototype.voiceName
         * @function
         * @public
         * @param {string} value - The name of the voice.
         */
        voiceName: string;
        /**
            * Provides the region.
            * @member SpeechTranslationConfigImpl.prototype.region
            * @function
            * @public
            * @returns {string} The region.
            */
        readonly region: string;
        setProxy(proxyHostName: string, proxyPort: number): void;
        setProxy(proxyHostName: string, proxyPort: number, proxyUserName: string, proxyPassword: string): void;
        /**
            * Gets an arbitrary property value.
            * @member SpeechTranslationConfigImpl.prototype.getProperty
            * @function
            * @public
            * @param {string} name - The name of the property.
            * @param {string} def - The default value of the property in case it is not set.
            * @returns {string} The value of the property.
            */
        getProperty(name: string, def?: string): string;
        /**
            * Gets/Sets an arbitrary property value.
            * @member SpeechTranslationConfigImpl.prototype.setProperty
            * @function
            * @public
            * @param {string} name - The name of the property.
            * @param {string} value - The value of the property.
            */
        setProperty(name: string, value: string): void;
        /**
            * Provides access to custom properties.
            * @member SpeechTranslationConfigImpl.prototype.properties
            * @function
            * @public
            * @returns {PropertyCollection} The properties.
            */
        readonly properties: PropertyCollection;
        /**
            * Dispose of associated resources.
            * @member SpeechTranslationConfigImpl.prototype.close
            * @function
            * @public
            */
        close(): void;
        setServiceProperty(name: string, value: string, channel: ServicePropertyChannel): void;
        setProfanity(profanity: ProfanityOption): void;
        enableAudioLogging(): void;
        requestWordLevelTimestamps(): void;
        enableDictation(): void;
}

/**
    * Represents collection of properties and their values.
    * @class PropertyCollection
    */
export class PropertyCollection {
        /**
            * Returns the property value in type String. The parameter must have the same type as String.
            * Currently only String, int and bool are allowed.
            * If the name is not available, the specified defaultValue is returned.
            * @member PropertyCollection.prototype.getProperty
            * @function
            * @public
            * @param {string} key - The parameter name.
            * @param {string} def - The default value which is returned if the parameter
            *        is not available in the collection.
            * @returns {string} value of the parameter.
            */
        getProperty(key: PropertyId | string, def?: string): string;
        /**
            * Sets the String value of the parameter specified by name.
            * @member PropertyCollection.prototype.setProperty
            * @function
            * @public
            * @param {string} key - The parameter name.
            * @param {string} value - The value of the parameter.
            */
        setProperty(key: string | PropertyId, value: string): void;
        /**
            * Clones the collection.
            * @member PropertyCollection.prototype.clone
            * @function
            * @public
            * @returns {PropertyCollection} A copy of the collection.
            */
        clone(): PropertyCollection;
}

/**
    * Defines speech property ids.
    * @class PropertyId
    */
export enum PropertyId {
        /**
            * The Cognitive Services Speech Service subscription Key. If you are using an intent recognizer, you need to specify
            * to specify the LUIS endpoint key for your particular LUIS app. Under normal circumstances, you shouldn't
            * have to use this property directly.
            * Instead, use [[SpeechConfig.fromSubscription]].
            * @member PropertyId.SpeechServiceConnection_Key
            */
        SpeechServiceConnection_Key = 0,
        /**
            * The Cognitive Services Speech Service endpoint (url). Under normal circumstances, you shouldn't
            * have to use this property directly.
            * Instead, use [[SpeechConfig.fromEndpoint]].
            * NOTE: This endpoint is not the same as the endpoint used to obtain an access token.
            * @member PropertyId.SpeechServiceConnection_Endpoint
            */
        SpeechServiceConnection_Endpoint = 1,
        /**
            * The Cognitive Services Speech Service region. Under normal circumstances, you shouldn't have to
            * use this property directly.
            * Instead, use [[SpeechConfig.fromSubscription]], [[SpeechConfig.fromEndpoint]], [[SpeechConfig.fromAuthorizationToken]].
            * @member PropertyId.SpeechServiceConnection_Region
            */
        SpeechServiceConnection_Region = 2,
        /**
            * The Cognitive Services Speech Service authorization token (aka access token). Under normal circumstances,
            * you shouldn't have to use this property directly.
            * Instead, use [[SpeechConfig.fromAuthorizationToken]],
            * [[SpeechRecognizer.authorizationToken]], [[IntentRecognizer.authorizationToken]], [[TranslationRecognizer.authorizationToken]].
            * @member PropertyId.SpeechServiceAuthorization_Token
            */
        SpeechServiceAuthorization_Token = 3,
        /**
            * The Cognitive Services Speech Service authorization type. Currently unused.
            * @member PropertyId.SpeechServiceAuthorization_Type
            */
        SpeechServiceAuthorization_Type = 4,
        /**
            * The Cognitive Services Speech Service endpoint id. Under normal circumstances, you shouldn't
            * have to use this property directly.
            * Instead, use [[SpeechConfig.endpointId]].
            * NOTE: The endpoint id is available in the Speech Portal, listed under Endpoint Details.
            * @member PropertyId.SpeechServiceConnection_EndpointId
            */
        SpeechServiceConnection_EndpointId = 5,
        /**
            * The list of comma separated languages (BCP-47 format) used as target translation languages. Under normal circumstances,
            * you shouldn't have to use this property directly.
            * Instead use [[SpeechTranslationConfig.addTargetLanguage]],
            * [[SpeechTranslationConfig.targetLanguages]], [[TranslationRecognizer.targetLanguages]].
            * @member PropertyId.SpeechServiceConnection_TranslationToLanguages
            */
        SpeechServiceConnection_TranslationToLanguages = 6,
        /**
            * The name of the Cognitive Service Text to Speech Service Voice. Under normal circumstances, you shouldn't have to use this
            * property directly.
            * Instead, use [[SpeechTranslationConfig.voiceName]].
            * NOTE: Valid voice names can be found <a href="https://aka.ms/csspeech/voicenames">here</a>.
            * @member PropertyId.SpeechServiceConnection_TranslationVoice
            */
        SpeechServiceConnection_TranslationVoice = 7,
        /**
            * Translation features.
            * @member PropertyId.SpeechServiceConnection_TranslationFeatures
            */
        SpeechServiceConnection_TranslationFeatures = 8,
        /**
            * The Language Understanding Service Region. Under normal circumstances, you shouldn't have to use this property directly.
            * Instead, use [[LanguageUnderstandingModel]].
            * @member PropertyId.SpeechServiceConnection_IntentRegion
            */
        SpeechServiceConnection_IntentRegion = 9,
        /**
            * The host name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
            * You shouldn't have to use this property directly.
            * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
            * Added in version 1.4.0.
            */
        SpeechServiceConnection_ProxyHostName = 10,
        /**
            * The port of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
            * You shouldn't have to use this property directly.
            * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
            * Added in version 1.4.0.
            */
        SpeechServiceConnection_ProxyPort = 11,
        /**
            * The user name of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
            * You shouldn't have to use this property directly.
            * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
            * Added in version 1.4.0.
            */
        SpeechServiceConnection_ProxyUserName = 12,
        /**
            * The password of the proxy server used to connect to the Cognitive Services Speech Service. Only relevant in Node.js environments.
            * You shouldn't have to use this property directly.
            * Instead use <see cref="SpeechConfig.SetProxy(string,int,string,string)"/>.
            * Added in version 1.4.0.
            */
        SpeechServiceConnection_ProxyPassword = 13,
        /**
            * The Cognitive Services Speech Service recognition Mode. Can be "INTERACTIVE", "CONVERSATION", "DICTATION".
            * This property is intended to be read-only. The SDK is using it internally.
            * @member PropertyId.SpeechServiceConnection_RecoMode
            */
        SpeechServiceConnection_RecoMode = 14,
        /**
            * The spoken language to be recognized (in BCP-47 format). Under normal circumstances, you shouldn't have to use this property
            * directly.
            * Instead, use [[SpeechConfig.speechRecognitionLanguage]].
            * @member PropertyId.SpeechServiceConnection_RecoLanguage
            */
        SpeechServiceConnection_RecoLanguage = 15,
        /**
            * The session id. This id is a universally unique identifier (aka UUID) representing a specific binding of an audio input stream
            * and the underlying speech recognition instance to which it is bound. Under normal circumstances, you shouldn't have to use this
            * property directly.
            * Instead use [[SessionEventArgs.sessionId]].
            * @member PropertyId.Speech_SessionId
            */
        Speech_SessionId = 16,
        /**
            * The requested Cognitive Services Speech Service response output format (simple or detailed). Under normal circumstances, you shouldn't have
            * to use this property directly.
            * Instead use [[SpeechConfig.outputFormat]].
            * @member PropertyId.SpeechServiceResponse_RequestDetailedResultTrueFalse
            */
        SpeechServiceResponse_RequestDetailedResultTrueFalse = 17,
        /**
            * The requested Cognitive Services Speech Service response output profanity level. Currently unused.
            * @member PropertyId.SpeechServiceResponse_RequestProfanityFilterTrueFalse
            */
        SpeechServiceResponse_RequestProfanityFilterTrueFalse = 18,
        /**
            * The Cognitive Services Speech Service response output (in JSON format). This property is available on recognition result objects only.
            * @member PropertyId.SpeechServiceResponse_JsonResult
            */
        SpeechServiceResponse_JsonResult = 19,
        /**
            * The Cognitive Services Speech Service error details (in JSON format). Under normal circumstances, you shouldn't have to
            * use this property directly. Instead use [[CancellationDetails.errorDetails]].
            * @member PropertyId.SpeechServiceResponse_JsonErrorDetails
            */
        SpeechServiceResponse_JsonErrorDetails = 20,
        /**
            * The cancellation reason. Currently unused.
            * @member PropertyId.CancellationDetails_Reason
            */
        CancellationDetails_Reason = 21,
        /**
            * The cancellation text. Currently unused.
            * @member PropertyId.CancellationDetails_ReasonText
            */
        CancellationDetails_ReasonText = 22,
        /**
            * The Cancellation detailed text. Currently unused.
            * @member PropertyId.CancellationDetails_ReasonDetailedText
            */
        CancellationDetails_ReasonDetailedText = 23,
        /**
            * The Language Understanding Service response output (in JSON format). Available via [[IntentRecognitionResult]]
            * @member PropertyId.LanguageUnderstandingServiceResponse_JsonResult
            */
        LanguageUnderstandingServiceResponse_JsonResult = 24,
        /**
            * The URL string built from speech configuration.
            * This property is intended to be read-only. The SDK is using it internally.
            * NOTE: Added in version 1.7.0.
            */
        SpeechServiceConnection_Url = 25,
        /**
            * The initial silence timeout value (in milliseconds) used by the service.
            * Added in version 1.7.0
            */
        SpeechServiceConnection_InitialSilenceTimeoutMs = 26,
        /**
            * The end silence timeout value (in milliseconds) used by the service.
            * Added in version 1.7.0
            */
        SpeechServiceConnection_EndSilenceTimeoutMs = 27,
        /**
            * A boolean value specifying whether audio logging is enabled in the service or not.
            * Added in version 1.7.0
            */
        SpeechServiceConnection_EnableAudioLogging = 28,
        /**
            * The requested Cognitive Services Speech Service response output profanity setting.
            * Allowed values are "masked", "removed", and "raw".
            * Added in version 1.7.0.
            */
        SpeechServiceResponse_ProfanityOption = 29,
        /**
            * A string value specifying which post processing option should be used by service.
            * Allowed values are "TrueText".
            * Added in version 1.7.0
            */
        SpeechServiceResponse_PostProcessingOption = 30,
        /**
            *  A boolean value specifying whether to include word-level timestamps in the response result.
            * Added in version 1.7.0
            */
        SpeechServiceResponse_RequestWordLevelTimestamps = 31,
        /**
            * The number of times a word has to be in partial results to be returned.
            * Added in version 1.7.0
            */
        SpeechServiceResponse_StablePartialResultThreshold = 32,
        /**
            * A string value specifying the output format option in the response result. Internal use only.
            * Added in version 1.7.0.
            */
        SpeechServiceResponse_OutputFormatOption = 33,
        /**
            * A boolean value to request for stabilizing translation partial results by omitting words in the end.
            * Added in version 1.7.0.
            */
        SpeechServiceResponse_TranslationRequestStablePartialResult = 34,
        /**
            * Identifier used to connect to the backend service.
            * @member PropertyId.Conversation_ApplicationId
            */
        Conversation_ApplicationId = 35,
        /**
            * Type of dialog backend to connect to.
            * @member PropertyId.Conversation_DialogType
            */
        Conversation_DialogType = 36,
        /**
            * Silence timeout for listening
            * @member PropertyId.Conversation_Initial_Silence_Timeout
            */
        Conversation_Initial_Silence_Timeout = 37,
        /**
            * From Id to add to speech recognition activities.
            * @member PropertyId.Conversation_From_Id
            */
        Conversation_From_Id = 38
}

/**
    * Defines the base class Recognizer which mainly contains common event handlers.
    * @class Recognizer
    */
export abstract class Recognizer {
        protected audioConfig: AudioConfig;
        protected privReco: ServiceRecognizerBase;
        protected privProperties: PropertyCollection;
        /**
            * Creates and initializes an instance of a Recognizer
            * @constructor
            * @param {AudioConfig} audioInput - An optional audio input stream associated with the recognizer
            */
        protected constructor(audioConfig: AudioConfig, properties: PropertyCollection, connectionFactory: IConnectionFactory);
        /**
            * Defines event handler for session started events.
            * @member Recognizer.prototype.sessionStarted
            * @function
            * @public
            */
        sessionStarted: (sender: Recognizer, event: SessionEventArgs) => void;
        /**
            * Defines event handler for session stopped events.
            * @member Recognizer.prototype.sessionStopped
            * @function
            * @public
            */
        sessionStopped: (sender: Recognizer, event: SessionEventArgs) => void;
        /**
            * Defines event handler for speech started events.
            * @member Recognizer.prototype.speechStartDetected
            * @function
            * @public
            */
        speechStartDetected: (sender: Recognizer, event: RecognitionEventArgs) => void;
        /**
            * Defines event handler for speech stopped events.
            * @member Recognizer.prototype.speechEndDetected
            * @function
            * @public
            */
        speechEndDetected: (sender: Recognizer, event: RecognitionEventArgs) => void;
        /**
            * Dispose of associated resources.
            * @member Recognizer.prototype.close
            * @function
            * @public
            */
        close(): void;
        /**
            * @Internal
            * Internal data member to support fromRecognizer* pattern methods on other classes.
            * Do not use externally, object returned will change without warning or notice.
            */
        readonly internalData: object;
        /**
            * This method performs cleanup of resources.
            * The Boolean parameter disposing indicates whether the method is called
            * from Dispose (if disposing is true) or from the finalizer (if disposing is false).
            * Derived classes should override this method to dispose resource if needed.
            * @member Recognizer.prototype.dispose
            * @function
            * @public
            * @param {boolean} disposing - Flag to request disposal.
            */
        protected dispose(disposing: boolean): void;
        /**
            * This method returns the current state of the telemetry setting.
            * @member Recognizer.prototype.telemetryEnabled
            * @function
            * @public
            * @returns true if the telemetry is enabled, false otherwise.
            */
        static readonly telemetryEnabled: boolean;
        /**
            * This method globally enables or disables telemetry.
            * @member Recognizer.prototype.enableTelemetry
            * @function
            * @public
            * @param enabled - Global setting for telemetry collection.
            * If set to true, telemetry information like microphone errors,
            * recognition errors are collected and sent to Microsoft.
            * If set to false, no telemetry is sent to Microsoft.
            */
        static enableTelemetry(enabled: boolean): void;
        protected abstract createRecognizerConfig(speecgConfig: SpeechServiceConfig): RecognizerConfig;
        protected abstract createServiceRecognizer(authentication: IAuthentication, connectionFactory: IConnectionFactory, audioConfig: AudioConfig, recognizerConfig: RecognizerConfig): ServiceRecognizerBase;
        protected implCommonRecognizerSetup(): void;
        protected implRecognizerStart(recognitionMode: RecognitionMode, successCallback: (e: SpeechRecognitionResult) => void, errorCallback: (e: string) => void): void;
        protected implRecognizerStop(): void;
}

/**
    * Performs speech recognition from microphone, file, or other audio input streams, and gets transcribed text as result.
    * @class SpeechRecognizer
    */
export class SpeechRecognizer extends Recognizer {
        /**
            * SpeechRecognizer constructor.
            * @constructor
            * @param {SpeechConfig} speechConfig - An set of initial properties for this recognizer
            * @param {AudioConfig} audioConfig - An optional audio configuration associated with the recognizer
            */
        constructor(speechConfig: SpeechConfig, audioConfig?: AudioConfig);
        /**
            * The event recognizing signals that an intermediate recognition result is received.
            * @member SpeechRecognizer.prototype.recognizing
            * @function
            * @public
            */
        recognizing: (sender: Recognizer, event: SpeechRecognitionEventArgs) => void;
        /**
            * The event recognized signals that a final recognition result is received.
            * @member SpeechRecognizer.prototype.recognized
            * @function
            * @public
            */
        recognized: (sender: Recognizer, event: SpeechRecognitionEventArgs) => void;
        /**
            * The event canceled signals that an error occurred during recognition.
            * @member SpeechRecognizer.prototype.canceled
            * @function
            * @public
            */
        canceled: (sender: Recognizer, event: SpeechRecognitionCanceledEventArgs) => void;
        /**
            * Gets the endpoint id of a customized speech model that is used for speech recognition.
            * @member SpeechRecognizer.prototype.endpointId
            * @function
            * @public
            * @returns {string} the endpoint id of a customized speech model that is used for speech recognition.
            */
        readonly endpointId: string;
        /**
         * Gets/Sets the authorization token used to communicate with the service.
         * @member SpeechRecognizer.prototype.authorizationToken
         * @function
         * @public
         * @param {string} token - Authorization token.
         */
        authorizationToken: string;
        /**
            * Gets the spoken language of recognition.
            * @member SpeechRecognizer.prototype.speechRecognitionLanguage
            * @function
            * @public
            * @returns {string} The spoken language of recognition.
            */
        readonly speechRecognitionLanguage: string;
        /**
            * Gets the output format of recognition.
            * @member SpeechRecognizer.prototype.outputFormat
            * @function
            * @public
            * @returns {OutputFormat} The output format of recognition.
            */
        readonly outputFormat: OutputFormat;
        /**
            * The collection of properties and their values defined for this SpeechRecognizer.
            * @member SpeechRecognizer.prototype.properties
            * @function
            * @public
            * @returns {PropertyCollection} The collection of properties and their values defined for this SpeechRecognizer.
            */
        readonly properties: PropertyCollection;
        /**
            * Starts speech recognition, and stops after the first utterance is recognized.
            * The task returns the recognition text as result.
            * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,
            *       so it is suitable only for single shot recognition
            *       like command or query. For long-running recognition, use StartContinuousRecognitionAsync() instead.
            * @member SpeechRecognizer.prototype.recognizeOnceAsync
            * @function
            * @public
            * @param cb - Callback that received the SpeechRecognitionResult.
            * @param err - Callback invoked in case of an error.
            */
        recognizeOnceAsync(cb?: (e: SpeechRecognitionResult) => void, err?: (e: string) => void): void;
        /**
            * Starts speech recognition, until stopContinuousRecognitionAsync() is called.
            * User must subscribe to events to receive recognition results.
            * @member SpeechRecognizer.prototype.startContinuousRecognitionAsync
            * @function
            * @public
            * @param cb - Callback invoked once the recognition has started.
            * @param err - Callback invoked in case of an error.
            */
        startContinuousRecognitionAsync(cb?: () => void, err?: (e: string) => void): void;
        /**
            * Stops continuous speech recognition.
            * @member SpeechRecognizer.prototype.stopContinuousRecognitionAsync
            * @function
            * @public
            * @param cb - Callback invoked once the recognition has stopped.
            * @param err - Callback invoked in case of an error.
            */
        stopContinuousRecognitionAsync(cb?: () => void, err?: (e: string) => void): void;
        /**
            * Starts speech recognition with keyword spotting, until
            * stopKeywordRecognitionAsync() is called.
            * User must subscribe to events to receive recognition results.
            * Note: Key word spotting functionality is only available on the
            *      Speech Devices SDK. This functionality is currently not included in the SDK itself.
            * @member SpeechRecognizer.prototype.startKeywordRecognitionAsync
            * @function
            * @public
            * @param {KeywordRecognitionModel} model The keyword recognition model that
            *        specifies the keyword to be recognized.
            * @param cb - Callback invoked once the recognition has started.
            * @param err - Callback invoked in case of an error.
            */
        startKeywordRecognitionAsync(model: KeywordRecognitionModel, cb?: () => void, err?: (e: string) => void): void;
        /**
            * Stops continuous speech recognition.
            * Note: Key word spotting functionality is only available on the
            *       Speech Devices SDK. This functionality is currently not included in the SDK itself.
            * @member SpeechRecognizer.prototype.stopKeywordRecognitionAsync
            * @function
            * @public
            * @param cb - Callback invoked once the recognition has stopped.
            * @param err - Callback invoked in case of an error.
            */
        stopKeywordRecognitionAsync(cb?: () => void, err?: (e: string) => void): void;
        /**
            * closes all external resources held by an instance of this class.
            * @member SpeechRecognizer.prototype.close
            * @function
            * @public
            */
        close(): void;
        /**
            * Disposes any resources held by the object.
            * @member SpeechRecognizer.prototype.dispose
            * @function
            * @public
            * @param {boolean} disposing - true if disposing the object.
            */
        protected dispose(disposing: boolean): void;
        protected createRecognizerConfig(speechConfig: SpeechServiceConfig): RecognizerConfig;
        protected createServiceRecognizer(authentication: IAuthentication, connectionFactory: IConnectionFactory, audioConfig: AudioConfig, recognizerConfig: RecognizerConfig): ServiceRecognizerBase;
}

/**
    * Intent recognizer.
    * @class
    */
export class IntentRecognizer extends Recognizer {
        /**
            * Initializes an instance of the IntentRecognizer.
            * @constructor
            * @param {SpeechConfig} speechConfig - The set of configuration properties.
            * @param {AudioConfig} audioConfig - An optional audio input config associated with the recognizer
            */
        constructor(speechConfig: SpeechConfig, audioConfig?: AudioConfig);
        /**
            * The event recognizing signals that an intermediate recognition result is received.
            * @member IntentRecognizer.prototype.recognizing
            * @function
            * @public
            */
        recognizing: (sender: IntentRecognizer, event: IntentRecognitionEventArgs) => void;
        /**
            * The event recognized signals that a final recognition result is received.
            * @member IntentRecognizer.prototype.recognized
            * @function
            * @public
            */
        recognized: (sender: IntentRecognizer, event: IntentRecognitionEventArgs) => void;
        /**
            * The event canceled signals that an error occurred during recognition.
            * @member IntentRecognizer.prototype.canceled
            * @function
            * @public
            */
        canceled: (sender: IntentRecognizer, event: IntentRecognitionCanceledEventArgs) => void;
        /**
            * Gets the spoken language of recognition.
            * @member IntentRecognizer.prototype.speechRecognitionLanguage
            * @function
            * @public
            * @returns {string} the spoken language of recognition.
            */
        readonly speechRecognitionLanguage: string;
        /**
         * Gets/Sets the authorization token used to communicate with the service.
         * Note: Please use a token derived from your LanguageUnderstanding subscription key for the Intent recognizer.
         * @member IntentRecognizer.prototype.authorizationToken
         * @function
         * @public
         * @param {string} value - Authorization token.
         */
        authorizationToken: string;
        /**
            * The collection of properties and their values defined for this IntentRecognizer.
            * @member IntentRecognizer.prototype.properties
            * @function
            * @public
            * @returns {PropertyCollection} The collection of properties and their
            *          values defined for this IntentRecognizer.
            */
        readonly properties: PropertyCollection;
        /**
            * Starts intent recognition, and stops after the first utterance is recognized.
            * The task returns the recognition text and intent as result.
            * Note: RecognizeOnceAsync() returns when the first utterance has been recognized,
            *       so it is suitable only for single shot recognition like command or query.
            *       For long-running recognition, use StartContinuousRecognitionAsync() instead.
            * @member IntentRecognizer.prototype.recognizeOnceAsync
            * @function
            * @public
            * @param cb - Callback that received the recognition has finished with an IntentRecognitionResult.
            * @param err - Callback invoked in case of an error.
            */
        recognizeOnceAsync(cb?: (e: IntentRecognitionResult) => void, err?: (e: string) => void): void;
        /**
            * Starts speech recognition, until stopContinuousRecognitionAsync() is called.
            * User must subscribe to events to receive recognition results.
            * @member IntentRecognizer.prototype.startContinuousRecognitionAsync
            * @function
            * @public
            * @param cb - Callback invoked once the recognition has started.
            * @param err - Callback invoked in case of an error.
            */
        startContinuousRecognitionAsync(cb?: () => void, err?: (e: string) => void): void;
        /**
            * Stops continuous intent recognition.
            * @member IntentRecognizer.prototype.stopContinuousRecognitionAsync
            * @function
            * @public
            * @param cb - Callback invoked once the recognition has stopped.
            * @param err - Callback invoked in case of an error.
            */
        stopContinuousRecognitionAsync(cb?: () => void, err?: (e: string) => void): void;
        /**
            * Starts speech recognition with keyword spotting, until stopKeywordRecognitionAsync() is called.
            * User must subscribe to events to receive recognition results.
            * Note: Key word spotting functionality is only available on the Speech Devices SDK.
            *       This functionality is currently not included in the SDK itself.
            * @member IntentRecognizer.prototype.startKeywordRecognitionAsync
            * @function
            * @public
            * @param {KeywordRecognitionModel} model - The keyword recognition model that specifies the keyword to be recognized.
            * @param cb - Callback invoked once the recognition has started.
            * @param err - Callback invoked in case of an error.
            */
        startKeywordRecognitionAsync(model: KeywordRecognitionModel, cb?: () => void, err?: (e: string) => void): void;
        /**
            * Stops continuous speech recognition.
            * Note: Key word spotting functionality is only available on the Speech Devices SDK.
            *       This functionality is currently not included in the SDK itself.
            * @member IntentRecognizer.prototype.stopKeywordRecognitionAsync
            * @function
            * @public
            * @param cb - Callback invoked once the recognition has stopped.
            * @param err - Callback invoked in case of an error.
            */
        stopKeywordRecognitionAsync(cb?: () => void, err?: (e: string) => void): void;
        /**
            * Adds a phrase that should be recognized as intent.
            * @member IntentRecognizer.prototype.addIntent
            * @function
            * @public
            * @param {string} intentId - A String that represents the identifier of the intent to be recognized.
            * @param {string} phrase - A String that specifies the phrase representing the intent.
            */
        addIntent(simplePhrase: string, intentId?: string): void;
        /**
            * Adds an intent from Language Understanding service for recognition.
            * @member IntentRecognizer.prototype.addIntentWithLanguageModel
            * @function
            * @public
            * @param {string} intentId - A String that represents the identifier of the intent
            *        to be recognized. Ignored if intentName is empty.
            * @param {string} model - The intent model from Language Understanding service.
            * @param {string} intentName - The intent name defined in the intent model. If it
            *        is empty, all intent names defined in the model will be added.
            */
        addIntentWithLanguageModel(intentId: string, model: LanguageUnderstandingModel, intentName?: string): void;
        /**
            * @summary Adds all intents from the specified Language Understanding Model.
            * @member IntentRecognizer.prototype.addAllIntents
            * @function
            * @public
            * @function
            * @public
            * @param {LanguageUnderstandingModel} model - The language understanding model containing the intents.
            * @param {string} intentId - A custom id String to be returned in the IntentRecognitionResult's getIntentId() method.
            */
        addAllIntents(model: LanguageUnderstandingModel, intentId?: string): void;
        /**
            * closes all external resources held by an instance of this class.
            * @member IntentRecognizer.prototype.close
            * @function
            * @public
            */
        close(): void;
        protected createRecognizerConfig(speechConfig: SpeechServiceConfig): RecognizerConfig;
        protected createServiceRecognizer(authentication: IAuthentication, connectionFactory: IConnectionFactory, audioConfig: AudioConfig, recognizerConfig: RecognizerConfig): ServiceRecognizerBase;
        protected dispose(disposing: boolean): void;
}

/**
    * Translation recognizer
    * @class TranslationRecognizer
    */
export class TranslationRecognizer extends Recognizer {
        /**
            * Initializes an instance of the TranslationRecognizer.
            * @constructor
            * @param {SpeechTranslationConfig} speechConfig - Set of properties to configure this recognizer.
            * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer
            */
        constructor(speechConfig: SpeechTranslationConfig, audioConfig?: AudioConfig);
        /**
            * The event recognizing signals that an intermediate recognition result is received.
            * @member TranslationRecognizer.prototype.recognizing
            * @function
            * @public
            */
        recognizing: (sender: TranslationRecognizer, event: TranslationRecognitionEventArgs) => void;
        /**
            * The event recognized signals that a final recognition result is received.
            * @member TranslationRecognizer.prototype.recognized
            * @function
            * @public
            */
        recognized: (sender: TranslationRecognizer, event: TranslationRecognitionEventArgs) => void;
        /**
            * The event canceled signals that an error occurred during recognition.
            * @member TranslationRecognizer.prototype.canceled
            * @function
            * @public
            */
        canceled: (sender: TranslationRecognizer, event: TranslationRecognitionCanceledEventArgs) => void;
        /**
            * The event synthesizing signals that a translation synthesis result is received.
            * @member TranslationRecognizer.prototype.synthesizing
            * @function
            * @public
            */
        synthesizing: (sender: TranslationRecognizer, event: TranslationSynthesisEventArgs) => void;
        /**
            * Gets the language name that was set when the recognizer was created.
            * @member TranslationRecognizer.prototype.speechRecognitionLanguage
            * @function
            * @public
            * @returns {string} Gets the language name that was set when the recognizer was created.
            */
        readonly speechRecognitionLanguage: string;
        /**
            * Gets target languages for translation that were set when the recognizer was created.
            * The language is specified in BCP-47 format. The translation will provide translated text for each of language.
            * @member TranslationRecognizer.prototype.targetLanguages
            * @function
            * @public
            * @returns {string[]} Gets target languages for translation that were set when the recognizer was created.
            */
        readonly targetLanguages: string[];
        /**
            * Gets the name of output voice.
            * @member TranslationRecognizer.prototype.voiceName
            * @function
            * @public
            * @returns {string} the name of output voice.
            */
        readonly voiceName: string;
        /**
         * Gets/Sets the authorization token used to communicate with the service.
         * @member TranslationRecognizer.prototype.authorizationToken
         * @function
         * @public
         * @param {string} value - Authorization token.
         */
        authorizationToken: string;
        /**
            * The collection of properties and their values defined for this TranslationRecognizer.
            * @member TranslationRecognizer.prototype.properties
            * @function
            * @public
            * @returns {PropertyCollection} The collection of properties and their values defined for this TranslationRecognizer.
            */
        readonly properties: PropertyCollection;
        /**
            * Starts recognition and translation, and stops after the first utterance is recognized.
            * The task returns the translation text as result.
            * Note: recognizeOnceAsync returns when the first utterance has been recognized, so it is suitableonly
            *       for single shot recognition like command or query. For long-running recognition,
            *       use startContinuousRecognitionAsync() instead.
            * @member TranslationRecognizer.prototype.recognizeOnceAsync
            * @function
            * @public
            * @param cb - Callback that received the result when the translation has completed.
            * @param err - Callback invoked in case of an error.
            */
        recognizeOnceAsync(cb?: (e: TranslationRecognitionResult) => void, err?: (e: string) => void): void;
        /**
            * Starts recognition and translation, until stopContinuousRecognitionAsync() is called.
            * User must subscribe to events to receive translation results.
            * @member TranslationRecognizer.prototype.startContinuousRecognitionAsync
            * @function
            * @public
            * @param cb - Callback that received the translation has started.
            * @param err - Callback invoked in case of an error.
            */
        startContinuousRecognitionAsync(cb?: () => void, err?: (e: string) => void): void;
        /**
            * Stops continuous recognition and translation.
            * @member TranslationRecognizer.prototype.stopContinuousRecognitionAsync
            * @function
            * @public
            * @param cb - Callback that received the translation has stopped.
            * @param err - Callback invoked in case of an error.
            */
        stopContinuousRecognitionAsync(cb?: () => void, err?: (e: string) => void): void;
        /**
            * closes all external resources held by an instance of this class.
            * @member TranslationRecognizer.prototype.close
            * @function
            * @public
            */
        close(): void;
        protected dispose(disposing: boolean): boolean;
        protected createRecognizerConfig(speechConfig: SpeechServiceConfig): RecognizerConfig;
        protected createServiceRecognizer(authentication: IAuthentication, connectionFactory: IConnectionFactory, audioConfig: AudioConfig, recognizerConfig: RecognizerConfig): ServiceRecognizerBase;
}

/**
    * Represents collection of parameters and their values.
    * @class Translation
    */
export class Translations {
        /**
            * Returns the parameter value in type String. The parameter must have the same type as String.
            * Currently only String, int and bool are allowed.
            * If the name is not available, the specified defaultValue is returned.
            * @member Translation.prototype.get
            * @function
            * @public
            * @param {string} key - The parameter name.
            * @param {string} def - The default value which is returned if the parameter is not available in the collection.
            * @returns {string} value of the parameter.
            */
        get(key: string, def?: string): string;
        /**
            * Sets the String value of the parameter specified by name.
            * @member Translation.prototype.set
            * @function
            * @public
            * @param {string} key - The parameter name.
            * @param {string} value - The value of the parameter.
            */
        set(key: string, value: string): void;
}

/**
    * Defines the possible reasons a recognition result might not be recognized.
    * @class NoMatchReason
    */
export enum NoMatchReason {
        /**
            * Indicates that speech was detected, but not recognized.
            * @member NoMatchReason.NotRecognized
            */
        NotRecognized = 0,
        /**
            * Indicates that the start of the audio stream contained only silence,
            * and the service timed out waiting for speech.
            * @member NoMatchReason.InitialSilenceTimeout
            */
        InitialSilenceTimeout = 1,
        /**
            * Indicates that the start of the audio stream contained only noise,
            * and the service timed out waiting for speech.
            * @member NoMatchReason.InitialBabbleTimeout
            */
        InitialBabbleTimeout = 2
}

/**
    * Contains detailed information for NoMatch recognition results.
    * @class NoMatchDetails
    */
export class NoMatchDetails {
        /**
            * Creates an instance of NoMatchDetails object for the NoMatch SpeechRecognitionResults.
            * @member NoMatchDetails.fromResult
            * @function
            * @public
            * @param {SpeechRecognitionResult | IntentRecognitionResult | TranslationRecognitionResult}
            *        result - The recognition result that was not recognized.
            * @returns {NoMatchDetails} The no match details object being created.
            */
        static fromResult(result: SpeechRecognitionResult | IntentRecognitionResult | TranslationRecognitionResult): NoMatchDetails;
        /**
            * The reason the recognition was canceled.
            * @member NoMatchDetails.prototype.reason
            * @function
            * @public
            * @returns {NoMatchReason} Specifies the reason canceled.
            */
        readonly reason: NoMatchReason;
}

/**
    * Define payload of speech recognition canceled result events.
    * @class TranslationRecognitionCanceledEventArgs
    */
export class TranslationRecognitionCanceledEventArgs {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {string} sessionid - The session id.
            * @param {CancellationReason} cancellationReason - The cancellation reason.
            * @param {string} errorDetails - Error details, if provided.
            * @param {TranslationRecognitionResult} result - The result.
            */
        constructor(sessionid: string, cancellationReason: CancellationReason, errorDetails: string, errorCode: CancellationErrorCode, result: TranslationRecognitionResult);
        /**
            * Specifies the recognition result.
            * @member TranslationRecognitionCanceledEventArgs.prototype.result
            * @function
            * @public
            * @returns {TranslationRecognitionResult} the recognition result.
            */
        readonly result: TranslationRecognitionResult;
        /**
            * Specifies the session identifier.
            * @member TranslationRecognitionCanceledEventArgs.prototype.sessionId
            * @function
            * @public
            * @returns {string} the session identifier.
            */
        readonly sessionId: string;
        /**
            * The reason the recognition was canceled.
            * @member TranslationRecognitionCanceledEventArgs.prototype.reason
            * @function
            * @public
            * @returns {CancellationReason} Specifies the reason canceled.
            */
        readonly reason: CancellationReason;
        /**
            * The error code in case of an unsuccessful recognition.
            * Added in version 1.1.0.
            * @return An error code that represents the error reason.
            */
        readonly errorCode: CancellationErrorCode;
        /**
            * In case of an unsuccessful recognition, provides details of the occurred error.
            * @member TranslationRecognitionCanceledEventArgs.prototype.errorDetails
            * @function
            * @public
            * @returns {string} A String that represents the error details.
            */
        readonly errorDetails: string;
}

/**
    * Define payload of intent recognition canceled result events.
    * @class IntentRecognitionCanceledEventArgs
    */
export class IntentRecognitionCanceledEventArgs extends IntentRecognitionEventArgs {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {CancellationReason} result - The result of the intent recognition.
            * @param {string} offset - The offset.
            * @param {IntentRecognitionResult} sessionId - The session id.
            */
        constructor(reason: CancellationReason, errorDetails: string, errorCode: CancellationErrorCode, result?: IntentRecognitionResult, offset?: number, sessionId?: string);
        /**
            * The reason the recognition was canceled.
            * @member IntentRecognitionCanceledEventArgs.prototype.reason
            * @function
            * @public
            * @returns {CancellationReason} Specifies the reason canceled.
            */
        readonly reason: CancellationReason;
        /**
            * The error code in case of an unsuccessful recognition.
            * Added in version 1.1.0.
            * @return An error code that represents the error reason.
            */
        readonly errorCode: CancellationErrorCode;
        /**
            * In case of an unsuccessful recognition, provides details of the occurred error.
            * @member IntentRecognitionCanceledEventArgs.prototype.errorDetails
            * @function
            * @public
            * @returns {string} A String that represents the error details.
            */
        readonly errorDetails: string;
}

/**
    * Contains detailed information about why a result was canceled.
    * @class CancellationDetails
    */
export class CancellationDetails {
        /**
            * Creates an instance of CancellationDetails object for the canceled RecognitionResult.
            * @member CancellationDetails.fromResult
            * @function
            * @public
            * @param {RecognitionResult} result - The result that was canceled.
            * @returns {CancellationDetails} The cancellation details object being created.
            */
        static fromResult(result: RecognitionResult): CancellationDetails;
        /**
            * The reason the recognition was canceled.
            * @member CancellationDetails.prototype.reason
            * @function
            * @public
            * @returns {CancellationReason} Specifies the reason canceled.
            */
        readonly reason: CancellationReason;
        /**
            * In case of an unsuccessful recognition, provides details of the occurred error.
            * @member CancellationDetails.prototype.errorDetails
            * @function
            * @public
            * @returns {string} A String that represents the error details.
            */
        readonly errorDetails: string;
        /**
            * The error code in case of an unsuccessful recognition.
            * Added in version 1.1.0.
            * @return An error code that represents the error reason.
            */
        readonly ErrorCode: CancellationErrorCode;
}

/**
    *  Defines error code in case that CancellationReason is Error.
    *  Added in version 1.1.0.
    */
export enum CancellationErrorCode {
        /**
            * Indicates that no error occurred during speech recognition.
            */
        NoError = 0,
        /**
            * Indicates an authentication error.
            */
        AuthenticationFailure = 1,
        /**
            * Indicates that one or more recognition parameters are invalid.
            */
        BadRequestParameters = 2,
        /**
            * Indicates that the number of parallel requests exceeded the number of allowed
            * concurrent transcriptions for the subscription.
            */
        TooManyRequests = 3,
        /**
            * Indicates a connection error.
            */
        ConnectionFailure = 4,
        /**
            * Indicates a time-out error when waiting for response from service.
            */
        ServiceTimeout = 5,
        /**
            * Indicates that an error is returned by the service.
            */
        ServiceError = 6,
        /**
            * Indicates an unexpected runtime error.
            */
        RuntimeError = 7
}

/**
  * Defines payload for connection events like Connected/Disconnected.
  * Added in version 1.2.0
  */
export class ConnectionEventArgs extends SessionEventArgs {
}

/**
    * Connection is a proxy class for managing connection to the speech service of the specified Recognizer.
    * By default, a Recognizer autonomously manages connection to service when needed.
    * The Connection class provides additional methods for users to explicitly open or close a connection and
    * to subscribe to connection status changes.
    * The use of Connection is optional, and mainly for scenarios where fine tuning of application
    * behavior based on connection status is needed. Users can optionally call Open() to manually set up a connection
    * in advance before starting recognition on the Recognizer associated with this Connection.
    * If the Recognizer needs to connect or disconnect to service, it will
    * setup or shutdown the connection independently. In this case the Connection will be notified by change of connection
    * status via Connected/Disconnected events.
    * Added in version 1.2.0.
    */
export class Connection {
        /**
            * Gets the Connection instance from the specified recognizer.
            * @param recognizer The recognizer associated with the connection.
            * @return The Connection instance of the recognizer.
            */
        static fromRecognizer(recognizer: Recognizer): Connection;
        /**
            * Starts to set up connection to the service.
            * Users can optionally call openConnection() to manually set up a connection in advance before starting recognition on the
            * Recognizer associated with this Connection. After starting recognition, calling Open() will have no effect
            *
            * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to
            * be notfied when the connection is established.
            */
        openConnection(): void;
        /**
            * Closes the connection the service.
            * Users can optionally call closeConnection() to manually shutdown the connection of the associated Recognizer.
            *
            * If closeConnection() is called during recognition, recognition will fail and cancel wtih an error.
            */
        closeConnection(): void;
        /**
            * The Connected event to indicate that the recognizer is connected to service.
            */
        connected: (args: ConnectionEventArgs) => void;
        /**
            * The Diconnected event to indicate that the recognizer is disconnected from service.
            */
        disconnected: (args: ConnectionEventArgs) => void;
        /**
            * Dispose of associated resources.
            */
        close(): void;
}

/**
    * Allows additions of new phrases to improve speech recognition.
    *
    * Phrases added to the recognizer are effective at the start of the next recognition, or the next time the SpeechSDK must reconnect
    * to the speech service.
    */
export class PhraseListGrammar {
        /**
            * Creates a PhraseListGrammar from a given speech recognizer. Will accept any recognizer that derives from @class Recognizer.
            * @param recognizer The recognizer to add phrase lists to.
            */
        static fromRecognizer(recognizer: Recognizer): PhraseListGrammar;
        /**
            * Adds a single phrase to the current recognizer.
            * @param phrase Phrase to add.
            */
        addPhrase(phrase: string): void;
        /**
            * Adds multiple phrases to the current recognizer.
            * @param phrases Array of phrases to add.
            */
        addPhrases(phrases: string[]): void;
        /**
            * Clears all phrases added to the current recognizer.
            */
        clear(): void;
}

/**
    * Class that defines base configurations for dialog service connector
    * @class DialogServiceConfig
    */
export abstract class DialogServiceConfig {
        /**
            * Creates an instance of DialogService config.
            * @constructor
            */
        protected constructor();
        /**
            * Sets an arbitrary property.
            * @member DialogServiceConfig.prototype.setProperty
            * @function
            * @public
            * @param {string} name - The name of the property to set.
            * @param {string} value - The new value of the property.
            */
        abstract setProperty(name: string, value: string): void;
        /**
            * Returns the current value of an arbitrary property.
            * @member DialogServiceConfig.prototype.getProperty
            * @function
            * @public
            * @param {string} name - The name of the property to query.
            * @param {string} def - The value to return in case the property is not known.
            * @returns {string} The current value, or provided default, of the given property.
            */
        abstract getProperty(name: string, def?: string): string;
        /**
            * @member DialogServiceConfig.prototype.setServiceProperty
            * @function
            * @public
            * @param {name} The name of the property.
            * @param {value} Value to set.
            * @param {channel} The channel used to pass the specified property to service.
            * @summary Sets a property value that will be passed to service using the specified channel.
            */
        abstract setServiceProperty(name: string, value: string, channel: ServicePropertyChannel): void;
        /**
            * Sets the proxy configuration.
            * Only relevant in Node.js environments.
            * Added in version 1.4.0.
            * @param proxyHostName The host name of the proxy server.
            * @param proxyPort The port number of the proxy server.
            */
        abstract setProxy(proxyHostName: string, proxyPort: number): void;
        /**
            * Sets the proxy configuration.
            * Only relevant in Node.js environments.
            * Added in version 1.4.0.
            * @param proxyHostName The host name of the proxy server, without the protocol scheme (http://)
            * @param porxyPort The port number of the proxy server.
            * @param proxyUserName The user name of the proxy server.
            * @param proxyPassword The password of the proxy server.
            */
        abstract setProxy(proxyHostName: string, proxyPort: number, proxyUserName: string, proxyPassword: string): void;
        /**
         * Gets/Sets the input language.
         * @member DialogServiceConfig.prototype.speechRecognitionLanguage
         * @function
         * @public
         * @param {string} value - The language to use for recognition.
         */
        abstract speechRecognitionLanguage: string;
        /**
            * Not used in DialogServiceConfig
            * @member DialogServiceConfig.applicationId
            */
        applicationId: string;
}
/**
    * Dialog Service configuration.
    * @class DialogServiceConfigImpl
    */
export class DialogServiceConfigImpl extends DialogServiceConfig {
        /**
            * Creates an instance of dialogService config.
            */
        constructor();
        /**
            * Provides access to custom properties.
            * @member DialogServiceConfigImpl.prototype.properties
            * @function
            * @public
            * @returns {PropertyCollection} The properties.
            */
        readonly properties: PropertyCollection;
        /**
         * Sets the speech recognition language.
         * @member DialogServiceConfigImpl.prototype.speechRecognitionLanguage
         * @function
         * @public
         * @param {string} value - The language to set.
         */
        speechRecognitionLanguage: string;
        /**
            * Sets a named property as value
            * @member DialogServiceConfigImpl.prototype.setProperty
            * @function
            * @public
            * @param {PropertyId | string} name - The property to set.
            * @param {string} value - The value.
            */
        setProperty(name: string | PropertyId, value: string): void;
        /**
            * Sets a named property as value
            * @member DialogServiceConfigImpl.prototype.getProperty
            * @function
            * @public
            * @param {PropertyId | string} name - The property to get.
            * @param {string} def - The default value to return in case the property is not known.
            * @returns {string} The current value, or provided default, of the given property.
            */
        getProperty(name: string | PropertyId, def?: string): string;
        /**
            * Sets the proxy configuration.
            * Only relevant in Node.js environments.
            * Added in version 1.4.0.
            * @param proxyHostName The host name of the proxy server, without the protocol scheme (http://)
            * @param proxyPort The port number of the proxy server.
            * @param proxyUserName The user name of the proxy server.
            * @param proxyPassword The password of the proxy server.
            */
        setProxy(proxyHostName: string, proxyPort: number, proxyUserName?: string, proxyPassword?: string): void;
        setServiceProperty(name: string, value: string, channel: import("./ServicePropertyChannel").ServicePropertyChannel): void;
        /**
            * Dispose of associated resources.
            * @member DialogServiceConfigImpl.prototype.close
            * @function
            * @public
            */
        close(): void;
}

/**
    * Class that defines configurations for the dialog service connector object for using a Bot Framework backend.
    * @class BotFrameworkConfig
    */
export class BotFrameworkConfig extends DialogServiceConfigImpl {
        /**
            * Creates an instance of BotFrameworkConfig.
            */
        constructor();
        /**
            * Creates an instance of the bot framework config with the specified subscription and region.
            * @member BotFrameworkConfig.fromSubscription
            * @function
            * @public
            * @param subscription Subscription key associated with the bot
            * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
            * @returns {BotFrameworkConfig} A new bot framework config.
            */
        static fromSubscription(subscription: string, region: string): BotFrameworkConfig;
        /**
            * Creates an instance of the bot framework config with the specified authorization token and region.
            * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            * expires, the caller needs to refresh it by calling this setter with a new valid token.
            * As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.
            * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
            * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
            * @member BotFrameworkConfig.fromAuthorizationToken
            * @function
            * @public
            * @param authorizationToken The authorization token associated with the bot
            * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
            * @returns {BotFrameworkConfig} A new bot framework config.
            */
        static fromAuthorizationToken(authorizationToken: string, region: string): BotFrameworkConfig;
}

/**
    * Class that defines configurations for the dialog service connector object for using a SpeechCommands backend.
    * @class SpeechCommandsConfig
    */
export class SpeechCommandsConfig extends DialogServiceConfigImpl {
        /**
            * Creates an instance of SpeechCommandsConfig.
            */
        constructor();
        /**
            * Creates an instance of the bot framework config with the specified subscription and region.
            * @member SpeechCommandsConfig.fromSubscription
            * @function
            * @public
            * @param applicationId Speech Commands application id.
            * @param subscription Subscription key associated with the bot
            * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
            * @returns {SpeechCommandsConfig} A new bot framework config.
            */
        static fromSubscription(applicationId: string, subscription: string, region: string): SpeechCommandsConfig;
        /**
            * Creates an instance of the bot framework config with the specified Speech Commands application id, authorization token and region.
            * Note: The caller needs to ensure that the authorization token is valid. Before the authorization token
            * expires, the caller needs to refresh it by calling this setter with a new valid token.
            * As configuration values are copied when creating a new recognizer, the new token value will not apply to recognizers that have already been created.
            * For recognizers that have been created before, you need to set authorization token of the corresponding recognizer
            * to refresh the token. Otherwise, the recognizers will encounter errors during recognition.
            * @member SpeechCommandsConfig.fromAuthorizationToken
            * @function
            * @public
            * @param applicationId Speech Commands application id.
            * @param authorizationToken The authorization token associated with the application.
            * @param region The region name (see the <a href="https://aka.ms/csspeech/region">region page</a>).
            * @returns {SpeechCommandsConfig} A new speech commands config.
            */
        static fromAuthorizationToken(applicationId: string, authorizationToken: string, region: string): SpeechCommandsConfig;
        /**
         * Gets the corresponding backend application identifier.
         * @member SpeechCommandsConfig.prototype.Conversation_ApplicationId
         * @function
         * @public
         * @param {string} value - The application identifier to get.
         */
        applicationId: string;
}

/**
    * Dialog Service Connector
    * @class DialogServiceConnector
    */
export class DialogServiceConnector extends Recognizer {
        /**
            * Initializes an instance of the DialogServiceConnector.
            * @constructor
            * @param {DialogServiceConfig} dialogConfig - Set of properties to configure this recognizer.
            * @param {AudioConfig} audioConfig - An optional audio config associated with the recognizer
            */
        constructor(dialogConfig: DialogServiceConfig, audioConfig?: AudioConfig);
        /**
            * The event recognizing signals that an intermediate recognition result is received.
            * @member DialogServiceConnector.prototype.recognizing
            * @function
            * @public
            */
        recognizing: (sender: DialogServiceConnector, event: SpeechRecognitionEventArgs) => void;
        /**
            * The event recognized signals that a final recognition result is received.
            * @member DialogServiceConfig.prototype.recognized
            * @function
            * @public
            */
        recognized: (sender: DialogServiceConnector, event: SpeechRecognitionEventArgs) => void;
        /**
            * The event canceled signals that an error occurred during recognition.
            * @member DialogServiceConnector.prototype.canceled
            * @function
            * @public
            */
        canceled: (sender: DialogServiceConnector, event: SpeechRecognitionCanceledEventArgs) => void;
        /**
            * The event activityReceived signals that an activity has been received.
            * @member DialogServiceConnector.prototype.activityReceived
            * @function
            * @public
            */
        activityReceived: (sender: DialogServiceConnector, event: ActivityReceivedEventArgs) => void;
        /**
            * Starts a connection to the service.
            * Users can optionally call connect() to manually set up a connection in advance, before starting interactions.
            *
            * Note: On return, the connection might not be ready yet. Please subscribe to the Connected event to
            * be notified when the connection is established.
            * @member DialogServiceConnector.prototype.connect
            * @function
            * @public
            */
        connect(): void;
        /**
            * Closes the connection the service.
            * Users can optionally call disconnect() to manually shutdown the connection of the associated DialogServiceConnector.
            *
            * If disconnect() is called during a recognition, recognition will fail and cancel with an error.
            */
        disconnect(): void;
        /**
         * Sets the authorization token used to communicate with the service.
         * @member DialogServiceConnector.prototype.authorizationToken
         * @function
         * @public
         * @param {string} token - Authorization token.
         */
        authorizationToken: string;
        /**
            * The collection of properties and their values defined for this DialogServiceConnector.
            * @member DialogServiceConnector.prototype.properties
            * @function
            * @public
            * @returns {PropertyCollection} The collection of properties and their values defined for this DialogServiceConnector.
            */
        readonly properties: PropertyCollection;
        /**
            * Starts recognition and stops after the first utterance is recognized.
            * @member DialogServiceConnector.prototype.listenOnceAsync
            * @function
            * @public
            * @param cb - Callback that received the result when the reco has completed.
            * @param err - Callback invoked in case of an error.
            */
        listenOnceAsync(cb?: (e: SpeechRecognitionResult) => void, err?: (e: string) => void): void;
        sendActivityAsync(activity: string): void;
        /**
            * closes all external resources held by an instance of this class.
            * @member DialogServiceConnector.prototype.close
            * @function
            * @public
            */
        close(): void;
        protected dispose(disposing: boolean): boolean;
        protected createRecognizerConfig(speechConfig: SpeechServiceConfig): RecognizerConfig;
        protected createServiceRecognizer(authentication: IAuthentication, connectionFactory: IConnectionFactory, audioConfig: AudioConfig, recognizerConfig: RecognizerConfig): ServiceRecognizerBase;
}

/**
    * Defines contents of received message/events.
    * @class ActivityReceivedEventArgs
    */
export class ActivityReceivedEventArgs {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param {any} activity - The activity..
            */
        constructor(activity: any, audioStream?: PullAudioOutputStream);
        /**
            * Gets the received activity
            * @member ActivityReceivedEventArgs.prototype.activity
            * @function
            * @public
            * @returns {any} the received activity.
            */
        readonly activity: any;
        readonly audioStream: PullAudioOutputStream;
}

/**
    * Defines channels used to pass property settings to service.
    * Added in version 1.7.0.
    */
export enum ServicePropertyChannel {
        /**
            * Uses URI query parameter to pass property settings to service.
            */
        UriQueryParameter = 0
}

/**
  * Profanity option.
  * Added in version 1.7.0.
  */
export enum ProfanityOption {
    Masked = 0,
    Removed = 1,
    Raw = 2
}

/**
    * Base audio player class
    * TODO: Plays only PCM for now.
    * @class
    */
export class BaseAudioPlayer {
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            */
        constructor(audioFormat: AudioStreamFormat);
        /**
            * play Audio sample
            * @param newAudioData audio data to be played.
            */
        playAudioSample(newAudioData: ArrayBuffer): void;
        /**
            * stops audio and clears the buffers
            */
        stopAudio(): void;
}

export const OutputFormatPropertyName: string;
export const CancellationErrorCodePropertyName: string;
export const ServicePropertiesPropertyName: string;
export const ForceDictationPropertyName: string;

/**
    * @class
    */
export class CognitiveSubscriptionKeyAuthentication implements IAuthentication {
        /**
            * Creates and initializes an instance of the CognitiveSubscriptionKeyAuthentication class.
            * @constructor
            * @param {string} subscriptionKey - The subscription key
            */
        constructor(subscriptionKey: string);
        /**
            * Fetches the subscription key.
            * @member
            * @function
            * @public
            * @param {string} authFetchEventId - The id to fetch.
            */
        fetch: (authFetchEventId: string) => Promise<AuthInfo>;
        /**
            * Fetches the subscription key.
            * @member
            * @function
            * @public
            * @param {string} authFetchEventId - The id to fetch.
            */
        fetchOnExpiry: (authFetchEventId: string) => Promise<AuthInfo>;
}

export class CognitiveTokenAuthentication implements IAuthentication {
    constructor(fetchCallback: (authFetchEventId: string) => Promise<string>, fetchOnExpiryCallback: (authFetchEventId: string) => Promise<string>);
    fetch: (authFetchEventId: string) => Promise<AuthInfo>;
    fetchOnExpiry: (authFetchEventId: string) => Promise<AuthInfo>;
}

export interface IAuthentication {
    fetch(authFetchEventId: string): Promise<AuthInfo>;
    fetchOnExpiry(authFetchEventId: string): Promise<AuthInfo>;
}
export class AuthInfo {
    constructor(headerName: string, token: string);
    readonly headerName: string;
    readonly token: string;
}

export interface IConnectionFactory {
    create(config: RecognizerConfig, authInfo: AuthInfo, connectionId?: string): IConnection;
}

export class IntentConnectionFactory extends ConnectionFactoryBase {
    create: (config: RecognizerConfig, authInfo: AuthInfo, connectionId?: string) => IConnection;
}

export class SpeechRecognitionEvent extends PlatformEvent {
    constructor(eventName: string, requestId: string, sessionId: string, eventType?: EventType);
    readonly requestId: string;
    readonly sessionId: string;
}
export class RecognitionTriggeredEvent extends SpeechRecognitionEvent {
    constructor(requestId: string, sessionId: string, audioSourceId: string, audioNodeId: string);
    readonly audioSourceId: string;
    readonly audioNodeId: string;
}
export class ListeningStartedEvent extends SpeechRecognitionEvent {
    constructor(requestId: string, sessionId: string, audioSourceId: string, audioNodeId: string);
    readonly audioSourceId: string;
    readonly audioNodeId: string;
}
export class ConnectingToServiceEvent extends SpeechRecognitionEvent {
    constructor(requestId: string, authFetchEventid: string, sessionId: string);
    readonly authFetchEventid: string;
}
export class RecognitionStartedEvent extends SpeechRecognitionEvent {
    constructor(requestId: string, audioSourceId: string, audioNodeId: string, authFetchEventId: string, sessionId: string);
    readonly audioSourceId: string;
    readonly audioNodeId: string;
    readonly authFetchEventId: string;
}
export enum RecognitionCompletionStatus {
    Success = 0,
    AudioSourceError = 1,
    AudioSourceTimeout = 2,
    AuthTokenFetchError = 3,
    AuthTokenFetchTimeout = 4,
    UnAuthorized = 5,
    ConnectTimeout = 6,
    ConnectError = 7,
    ClientRecognitionActivityTimeout = 8,
    UnknownError = 9
}
export class RecognitionEndedEvent extends SpeechRecognitionEvent {
    constructor(requestId: string, audioSourceId: string, audioNodeId: string, authFetchEventId: string, sessionId: string, serviceTag: string, status: RecognitionCompletionStatus, error: string);
    readonly audioSourceId: string;
    readonly audioNodeId: string;
    readonly authFetchEventId: string;
    readonly serviceTag: string;
    readonly status: RecognitionCompletionStatus;
    readonly error: string;
}

export abstract class ServiceRecognizerBase implements IDisposable {
    protected privRequestSession: RequestSession;
    protected privConnectionId: string;
    protected privRecognizerConfig: RecognizerConfig;
    protected privRecognizer: Recognizer;
    constructor(authentication: IAuthentication, connectionFactory: IConnectionFactory, audioSource: IAudioSource, recognizerConfig: RecognizerConfig, recognizer: Recognizer);
    readonly audioSource: IAudioSource;
    readonly speechContext: SpeechContext;
    readonly dynamicGrammar: DynamicGrammarBuilder;
    readonly agentConfig: AgentConfig;
    isDisposed(): boolean;
    dispose(reason?: string): void;
    readonly connectionEvents: EventSource<ConnectionEvent>;
    readonly recognitionMode: RecognitionMode;
    protected recognizeOverride: (recoMode: RecognitionMode, sc: (e: SpeechRecognitionResult) => void, ec: (e: string) => void) => any;
    recognize(recoMode: RecognitionMode, successCallback: (e: SpeechRecognitionResult) => void, errorCallBack: (e: string) => void): Promise<boolean>;
    stopRecognizing(): void;
    connect(): void;
    protected disconnectOverride: () => any;
    disconnect(): void;
    static telemetryData: (json: string) => void;
    static telemetryDataEnabled: boolean;
    sendMessage(message: string): void;
    protected abstract processTypeSpecificMessages(connectionMessage: SpeechConnectionMessage, successCallback?: (e: SpeechRecognitionResult) => void, errorCallBack?: (e: string) => void): void;
    protected sendTelemetryData: () => Promise<boolean> | Promise<Promise<boolean>>;
    protected abstract cancelRecognition(sessionId: string, requestId: string, cancellationReason: CancellationReason, errorCode: CancellationErrorCode, error: string, cancelRecoCallback: (r: SpeechRecognitionResult) => void): void;
    protected cancelRecognitionLocal(cancellationReason: CancellationReason, errorCode: CancellationErrorCode, error: string, cancelRecoCallback: (r: SpeechRecognitionResult) => void): void;
    protected receiveMessageOverride: (sc?: (e: SpeechRecognitionResult) => void, ec?: (e: string) => void) => any;
    protected receiveMessage: (successCallback: (e: SpeechRecognitionResult) => void, errorCallBack: (e: string) => void) => Promise<IConnection>;
    protected sendSpeechContext: (connection: IConnection) => Promise<boolean>;
    protected connectImplOverride: (isUnAuthorized: boolean) => any;
    protected connectImpl(isUnAuthorized?: boolean): Promise<IConnection>;
    protected configConnectionOverride: () => any;
    protected fetchConnectionOverride: () => any;
    protected sendSpeechServiceConfig: (connection: IConnection, requestSession: RequestSession, SpeechServiceConfigJson: string) => Promise<boolean>;
    protected sendAudio: (audioStreamNode: IAudioStreamNode) => Promise<boolean>;
}

export enum RecognitionMode {
    Interactive = 0,
    Conversation = 1,
    Dictation = 2
}
export enum SpeechResultFormat {
    Simple = 0,
    Detailed = 1
}
export class RecognizerConfig {
    constructor(speechServiceConfig: SpeechServiceConfig, parameters: PropertyCollection);
    readonly parameters: PropertyCollection;
    recognitionMode: RecognitionMode;
    readonly SpeechServiceConfig: SpeechServiceConfig;
    readonly recognitionActivityTimeout: number;
    readonly isContinuousRecognition: boolean;
}
export class SpeechServiceConfig {
    constructor(context: Context);
    serialize: () => string;
    readonly Context: Context;
    Recognition: string;
}
export class Context {
    system: System;
    os: OS;
    audio: ISpeechConfigAudio;
    constructor(os: OS);
}
export class System {
    name: string;
    version: string;
    build: string;
    lang: string;
    constructor();
}
export class OS {
    platform: string;
    name: string;
    version: string;
    constructor(platform: string, name: string, version: string);
}
export class Device {
    manufacturer: string;
    model: string;
    version: string;
    constructor(manufacturer: string, model: string, version: string);
}
export interface ISpeechConfigAudio {
    source?: ISpeechConfigAudioDevice;
    playback?: ISpeechConfigAudioDevice;
}
export interface ISpeechConfigAudioDevice {
    manufacturer: string;
    model: string;
    connectivity: connectivity;
    type: type;
    samplerate: number;
    bitspersample: number;
    channelcount: number;
}
export enum connectivity {
    Bluetooth = "Bluetooth",
    Wired = "Wired",
    WiFi = "WiFi",
    Cellular = "Cellular",
    InBuilt = "InBuilt",
    Unknown = "Unknown"
}
export enum type {
    Phone = "Phone",
    Speaker = "Speaker",
    Car = "Car",
    Headset = "Headset",
    Thermostat = "Thermostat",
    Microphones = "Microphones",
    Deskphone = "Deskphone",
    RemoteControl = "RemoteControl",
    Unknown = "Unknown",
    File = "File",
    Stream = "Stream"
}

export interface ITranslations {
    TranslationStatus: TranslationStatus;
    Translations: ITranslation[];
    FailureReason: string;
}
export interface ITranslation {
    Language: string;
    Text: string;
}
export interface ISpeechEndDetectedResult {
    Offset?: number;
}
export interface ITurnStart {
    context: ITurnStartContext;
}
export interface ITurnStartContext {
    serviceTag: string;
}
export interface IResultErrorDetails {
    errorText: string;
    recogSate: RecognitionCompletionStatus;
}

export class WebsocketMessageFormatter implements IWebsocketMessageFormatter {
    toConnectionMessage: (message: RawWebsocketMessage) => Promise<ConnectionMessage>;
    fromConnectionMessage: (message: ConnectionMessage) => Promise<RawWebsocketMessage>;
}

export class SpeechConnectionFactory extends ConnectionFactoryBase {
    create: (config: RecognizerConfig, authInfo: AuthInfo, connectionId?: string) => IConnection;
}

export class TranslationConnectionFactory extends ConnectionFactoryBase {
    create: (config: RecognizerConfig, authInfo: AuthInfo, connectionId?: string) => IConnection;
}

export class EnumTranslation {
    static implTranslateRecognitionResult(recognitionStatus: RecognitionStatus): ResultReason;
    static implTranslateCancelResult(recognitionStatus: RecognitionStatus): CancellationReason;
    static implTranslateCancelErrorCode(recognitionStatus: RecognitionStatus): CancellationErrorCode;
}

/**
    * @class SynthesisStatus
    * @private
    */
export enum SynthesisStatus {
        /**
            * The response contains valid audio data.
            * @member SynthesisStatus.Success
            */
        Success = 0,
        /**
            * Indicates the end of audio data. No valid audio data is included in the message.
            * @member SynthesisStatus.SynthesisEnd
            */
        SynthesisEnd = 1,
        /**
            * Indicates an error occurred during synthesis data processing.
            * @member SynthesisStatus.Error
            */
        Error = 2
}
export enum RecognitionStatus {
        Success = 0,
        NoMatch = 1,
        InitialSilenceTimeout = 2,
        BabbleTimeout = 3,
        Error = 4,
        EndOfDictation = 5,
        TooManyRequests = 6
}

export interface ITranslationSynthesisEnd {
    SynthesisStatus: SynthesisStatus;
    FailureReason: string;
}
export class TranslationSynthesisEnd implements ITranslationSynthesisEnd {
    static fromJSON(json: string): TranslationSynthesisEnd;
    readonly SynthesisStatus: SynthesisStatus;
    readonly FailureReason: string;
}

export interface ITranslationHypothesis {
    Duration: number;
    Offset: number;
    Text: string;
    Translation: ITranslations;
}
export class TranslationHypothesis implements ITranslationHypothesis {
    static fromJSON(json: string): TranslationHypothesis;
    readonly Duration: number;
    readonly Offset: number;
    readonly Text: string;
    readonly Translation: ITranslations;
}

export interface ITranslationPhrase {
    RecognitionStatus: RecognitionStatus;
    Offset: number;
    Duration: number;
    Text: string;
    Translation: ITranslations;
}
export class TranslationPhrase implements ITranslationPhrase {
    static fromJSON(json: string): TranslationPhrase;
    readonly RecognitionStatus: RecognitionStatus;
    readonly Offset: number;
    readonly Duration: number;
    readonly Text: string;
    readonly Translation: ITranslations;
}

export class TranslationServiceRecognizer extends ServiceRecognizerBase {
    constructor(authentication: IAuthentication, connectionFactory: IConnectionFactory, audioSource: IAudioSource, recognizerConfig: RecognizerConfig, translationRecognizer: TranslationRecognizer);
    protected processTypeSpecificMessages(connectionMessage: SpeechConnectionMessage, successCallback?: (e: TranslationRecognitionResult) => void, errorCallBack?: (e: string) => void): void;
    protected cancelRecognition(sessionId: string, requestId: string, cancellationReason: CancellationReason, errorCode: CancellationErrorCode, error: string, cancelRecoCallback: (e: SpeechRecognitionResult) => void): void;
}

export interface ISpeechDetected {
    Offset: number;
}
export class SpeechDetected implements ISpeechDetected {
    static fromJSON(json: string): SpeechDetected;
    readonly Offset: number;
}

export interface ISpeechHypothesis {
    Text: string;
    Offset: number;
    Duration: number;
}
export class SpeechHypothesis implements ISpeechHypothesis {
    static fromJSON(json: string): SpeechHypothesis;
    readonly Text: string;
    readonly Offset: number;
    readonly Duration: number;
}

export class SpeechServiceRecognizer extends ServiceRecognizerBase {
    constructor(authentication: IAuthentication, connectionFactory: IConnectionFactory, audioSource: IAudioSource, recognizerConfig: RecognizerConfig, speechRecognizer: SpeechRecognizer);
    protected processTypeSpecificMessages(connectionMessage: SpeechConnectionMessage, successCallback?: (e: SpeechRecognitionResult) => void, errorCallBack?: (e: string) => void): void;
    protected cancelRecognition(sessionId: string, requestId: string, cancellationReason: CancellationReason, errorCode: CancellationErrorCode, error: string, cancelRecoCallback: (e: SpeechRecognitionResult) => void): void;
}

export interface IDetailedSpeechPhrase {
    RecognitionStatus: RecognitionStatus;
    NBest: IPhrase[];
    Duration?: number;
    Offset?: number;
}
export interface IPhrase {
    Confidence?: number;
    Lexical: string;
    ITN: string;
    MaskedITN: string;
    Display: string;
}
export class DetailedSpeechPhrase implements IDetailedSpeechPhrase {
    static fromJSON(json: string): DetailedSpeechPhrase;
    readonly RecognitionStatus: RecognitionStatus;
    readonly NBest: IPhrase[];
    readonly Duration: number;
    readonly Offset: number;
}

export interface ISimpleSpeechPhrase {
    RecognitionStatus: RecognitionStatus;
    DisplayText: string;
    Offset?: number;
    Duration?: number;
}
export class SimpleSpeechPhrase implements ISimpleSpeechPhrase {
    static fromJSON(json: string): SimpleSpeechPhrase;
    readonly RecognitionStatus: RecognitionStatus;
    readonly DisplayText: string;
    readonly Offset: number;
    readonly Duration: number;
}

/**
    * @class AddedLmIntent
    */
export class AddedLmIntent {
        modelImpl: LanguageUnderstandingModelImpl;
        intentName: string;
        /**
            * Creates and initializes an instance of this class.
            * @constructor
            * @param modelImpl - The model.
            * @param intentName - The intent name.
            */
        constructor(modelImpl: LanguageUnderstandingModelImpl, intentName: string);
}

export class IntentServiceRecognizer extends ServiceRecognizerBase {
    constructor(authentication: IAuthentication, connectionFactory: IConnectionFactory, audioSource: IAudioSource, recognizerConfig: RecognizerConfig, recognizer: IntentRecognizer);
    setIntents(addedIntents: {
        [id: string]: AddedLmIntent;
    }, umbrellaIntent: AddedLmIntent): void;
    protected processTypeSpecificMessages(connectionMessage: SpeechConnectionMessage, successCallback?: (e: IntentRecognitionResult) => void, errorCallBack?: (e: string) => void): void;
    protected cancelRecognition(sessionId: string, requestId: string, cancellationReason: CancellationReason, errorCode: CancellationErrorCode, error: string, cancelRecoCallback: (e: SpeechRecognitionResult) => void): void;
}

export interface IIntentResponse {
    query: string;
    topScoringIntent: ISingleIntent;
    entities: IIntentEntity[];
}
export interface IIntentEntity {
    entity: string;
    type: string;
    startIndex: number;
    endIndex: number;
    score: number;
}
export interface ISingleIntent {
    intent: string;
    score: number;
}
export class IntentResponse implements IIntentResponse {
    static fromJSON(json: string): IntentResponse;
    readonly query: string;
    readonly topScoringIntent: ISingleIntent;
    readonly entities: IIntentEntity[];
}

export class RequestSession {
    constructor(audioSourceId: string);
    readonly sessionId: string;
    readonly requestId: string;
    readonly audioNodeId: string;
    readonly completionPromise: Promise<boolean>;
    readonly isSpeechEnded: boolean;
    readonly isRecognizing: boolean;
    readonly currentTurnAudioOffset: number;
    readonly recogNumber: number;
    readonly bytesSent: number;
    listenForServiceTelemetry(eventSource: IEventSource<PlatformEvent>): void;
    startNewRecognition(): void;
    onAudioSourceAttachCompleted: (audioNode: ReplayableAudioNode, isError: boolean, error?: string) => void;
    onPreConnectionStart: (authFetchEventId: string, connectionId: string) => void;
    onAuthCompleted: (isError: boolean, error?: string) => void;
    onConnectionEstablishCompleted: (statusCode: number, reason?: string) => void;
    onServiceTurnEndResponse: (continuousRecognition: boolean) => void;
    onHypothesis(offset: number): void;
    onPhraseRecognized(offset: number): void;
    onServiceRecognized(offset: number): void;
    onAudioSent(bytesSent: number): void;
    dispose: (error?: string) => void;
    getTelemetry: () => string;
    onStopRecognizing(): void;
    onSpeechEnded(): void;
    protected onEvent: (event: SpeechRecognitionEvent) => void;
}

/**
    * Represents the JSON used in the speech.context message sent to the speech service.
    * The dynamic grammar is always refreshed from the encapsulated dynamic grammar object.
    */
export class SpeechContext {
        constructor(dynamicGrammar: DynamicGrammarBuilder);
        /**
            * Adds a section to the speech.context object.
            * @param sectionName Name of the section to add.
            * @param value JSON serializeable object that represents the value.
            */
        setSection(sectionName: string, value: any): void;
        toJSON(): string;
}

/**
  * Responsible for building the object to be sent to the speech service to support dynamic grammars.
  * @class DynamicGrammarBuilder
  */
export class DynamicGrammarBuilder {
    addPhrase(phrase: string | string[]): void;
    clearPhrases(): void;
    addReferenceGrammar(grammar: string | string[]): void;
    clearGrammars(): void;
    generateGrammarObject(): IDynamicGrammar;
}

/**
    *  Top level grammar node
    */
export interface IDynamicGrammar {
        ReferenceGrammars?: string[];
        Groups?: IDynamicGrammarGroup[];
}
/**
    * Group of Dynamic Grammar items of a common type.
    */
export interface IDynamicGrammarGroup {
        Type: string;
        Name?: string;
        SubstringMatch?: string;
        Items: IDynamicGrammarPeople[] | IDynamicGrammarGeneric[];
}
export interface IDynamicGrammarPeople {
        Name: string;
        First?: string;
        Middle?: string;
        Last?: string;
        Synonyms?: string[];
        Weight?: number;
}
/**
    * Generic phrase based dynamic grammars
    */
export interface IDynamicGrammarGeneric {
        Text: string;
        Synonyms?: string[];
        Weight?: number;
}

export class DialogServiceAdapter extends ServiceRecognizerBase {
    constructor(authentication: IAuthentication, connectionFactory: IConnectionFactory, audioSource: IAudioSource, recognizerConfig: RecognizerConfig, dialogServiceConnector: DialogServiceConnector);
    isDisposed(): boolean;
    dispose(reason?: string): void;
    sendMessage: (message: string) => void;
    protected privDisconnect(): void;
    protected processTypeSpecificMessages(connectionMessage: SpeechConnectionMessage, successCallback?: (e: SpeechRecognitionResult) => void, errorCallBack?: (e: string) => void): void;
    protected cancelRecognition(sessionId: string, requestId: string, cancellationReason: CancellationReason, errorCode: CancellationErrorCode, error: string, cancelRecoCallback: (e: SpeechRecognitionResult) => void): void;
    protected listenOnce: (recoMode: RecognitionMode, successCallback: (e: SpeechRecognitionResult) => void, errorCallback: (e: string) => void) => any;
    protected sendAudio: (audioStreamNode: IAudioStreamNode) => Promise<boolean>;
}

/**
    * Represents the JSON used in the agent.config message sent to the speech service.
    */
export class AgentConfig {
        toJsonString(): string;
        get(): IAgentConfig;
        /**
            * Setter for the agent.config object.
            * @param value a JSON serializable object.
            */
        set(value: IAgentConfig): void;
}
export interface IAgentConfig {
        botInfo: {
                commType: string;
                connectionId: string;
                conversationId: string;
        };
        version: number;
}

export class AudioSourceEvent extends PlatformEvent {
    constructor(eventName: string, audioSourceId: string, eventType?: EventType);
    readonly audioSourceId: string;
}
export class AudioSourceInitializingEvent extends AudioSourceEvent {
    constructor(audioSourceId: string);
}
export class AudioSourceReadyEvent extends AudioSourceEvent {
    constructor(audioSourceId: string);
}
export class AudioSourceOffEvent extends AudioSourceEvent {
    constructor(audioSourceId: string);
}
export class AudioSourceErrorEvent extends AudioSourceEvent {
    constructor(audioSourceId: string, error: string);
    readonly error: string;
}
export class AudioStreamNodeEvent extends AudioSourceEvent {
    constructor(eventName: string, audioSourceId: string, audioNodeId: string);
    readonly audioNodeId: string;
}
export class AudioStreamNodeAttachingEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId: string, audioNodeId: string);
}
export class AudioStreamNodeAttachedEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId: string, audioNodeId: string);
}
export class AudioStreamNodeDetachedEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId: string, audioNodeId: string);
}
export class AudioStreamNodeErrorEvent extends AudioStreamNodeEvent {
    constructor(audioSourceId: string, audioNodeId: string, error: string);
    readonly error: string;
}

export class ConnectionEvent extends PlatformEvent {
    constructor(eventName: string, connectionId: string, eventType?: EventType);
    readonly connectionId: string;
}
export class ConnectionStartEvent extends ConnectionEvent {
    constructor(connectionId: string, uri: string, headers?: IStringDictionary<string>);
    readonly uri: string;
    readonly headers: IStringDictionary<string>;
}
export class ConnectionEstablishedEvent extends ConnectionEvent {
    constructor(connectionId: string, metadata?: IStringDictionary<string>);
}
export class ConnectionClosedEvent extends ConnectionEvent {
    constructor(connectionId: string, statusCode: number, reason: string);
    readonly reason: string;
    readonly statusCode: number;
}
export class ConnectionEstablishErrorEvent extends ConnectionEvent {
    constructor(connectionId: string, statuscode: number, reason: string);
    readonly reason: string;
    readonly statusCode: number;
}
export class ConnectionMessageReceivedEvent extends ConnectionEvent {
    constructor(connectionId: string, networkReceivedTimeISO: string, message: ConnectionMessage);
    readonly networkReceivedTime: string;
    readonly message: ConnectionMessage;
}
export class ConnectionMessageSentEvent extends ConnectionEvent {
    constructor(connectionId: string, networkSentTimeISO: string, message: ConnectionMessage);
    readonly networkSentTime: string;
    readonly message: ConnectionMessage;
}

export enum MessageType {
    Text = 0,
    Binary = 1
}
export class ConnectionMessage {
    constructor(messageType: MessageType, body: any, headers?: IStringDictionary<string>, id?: string);
    readonly messageType: MessageType;
    readonly headers: any;
    readonly body: any;
    readonly textBody: string;
    readonly binaryBody: ArrayBuffer;
    readonly id: string;
}

export class ConnectionOpenResponse {
    constructor(statusCode: number, reason: string);
    readonly statusCode: number;
    readonly reason: string;
}

/**
    * The error that is thrown when an argument passed in is null.
    *
    * @export
    * @class ArgumentNullError
    * @extends {Error}
    */
export class ArgumentNullError extends Error {
        /**
            * Creates an instance of ArgumentNullError.
            *
            * @param {string} argumentName - Name of the argument that is null
            *
            * @memberOf ArgumentNullError
            */
        constructor(argumentName: string);
}
/**
    * The error that is thrown when an invalid operation is performed in the code.
    *
    * @export
    * @class InvalidOperationError
    * @extends {Error}
    */
export class InvalidOperationError extends Error {
        /**
            * Creates an instance of InvalidOperationError.
            *
            * @param {string} error - The error
            *
            * @memberOf InvalidOperationError
            */
        constructor(error: string);
}
/**
    * The error that is thrown when an object is disposed.
    *
    * @export
    * @class ObjectDisposedError
    * @extends {Error}
    */
export class ObjectDisposedError extends Error {
        /**
            * Creates an instance of ObjectDisposedError.
            *
            * @param {string} objectName - The object that is disposed
            * @param {string} error - The error
            *
            * @memberOf ObjectDisposedError
            */
        constructor(objectName: string, error?: string);
}

export class Events {
    static setEventSource: (eventSource: IEventSource<PlatformEvent>) => void;
    static readonly instance: IEventSource<PlatformEvent>;
}

export class EventSource<TEvent extends PlatformEvent> implements IEventSource<TEvent> {
    constructor(metadata?: IStringDictionary<string>);
    onEvent: (event: TEvent) => void;
    attach: (onEventCallback: (event: TEvent) => void) => IDetachable;
    attachListener: (listener: IEventListener<TEvent>) => IDetachable;
    isDisposed: () => boolean;
    dispose: () => void;
    readonly metadata: IStringDictionary<string>;
}

const createGuid: () => string;
const createNoDashGuid: () => string;
export { createGuid, createNoDashGuid };

export interface IAudioSource {
    id(): string;
    turnOn(): Promise<boolean>;
    attach(audioNodeId: string): Promise<IAudioStreamNode>;
    detach(audioNodeId: string): void;
    turnOff(): Promise<boolean>;
    events: EventSource<AudioSourceEvent>;
    format: AudioStreamFormat;
    deviceInfo: Promise<ISpeechConfigAudioDevice>;
    setProperty?(name: string, value: string): void;
    getProperty?(name: string, def?: string): string;
}
export interface IAudioStreamNode extends IDetachable {
    id(): string;
    read(): Promise<IStreamChunk<ArrayBuffer>>;
}

export enum ConnectionState {
    None = 0,
    Connected = 1,
    Connecting = 2,
    Disconnected = 3
}
export interface IConnection extends IDisposable {
    id: string;
    state(): ConnectionState;
    open(): Promise<ConnectionOpenResponse>;
    send(message: ConnectionMessage): Promise<boolean>;
    read(): Promise<ConnectionMessage>;
    events: EventSource<ConnectionEvent>;
}

export interface IDetachable {
    detach(): void;
}

export interface IStringDictionary<TValue> {
    [propName: string]: TValue;
}
export interface INumberDictionary<TValue> extends Object {
    [propName: number]: TValue;
}

/**
    * @export
    * @interface IDisposable
    */
export interface IDisposable {
        /**
            * @returns {boolean}
            *
            * @memberOf IDisposable
            */
        isDisposed(): boolean;
        /**
            * Performs cleanup operations on this instance
            *
            * @param {string} [reason] - optional reason for disposing the instance.
            * This will be used to throw errors when a operations are performed on the disposed object.
            *
            * @memberOf IDisposable
            */
        dispose(reason?: string): void;
}

export interface IEventListener<TEvent extends PlatformEvent> {
    onEvent(e: TEvent): void;
}
export interface IEventSource<TEvent extends PlatformEvent> extends IDisposable {
    metadata: IStringDictionary<string>;
    onEvent(e: TEvent): void;
    attach(onEventCallback: (event: TEvent) => void): IDetachable;
    attachListener(listener: IEventListener<TEvent>): IDetachable;
}

export interface ITimer {
        /**
            * start timer
            *
            * @param {number} delay
            * @param {(...args: any[]) => any} successCallback
            * @returns {*}
            *
            * @memberOf ITimer
            */
        start(): void;
        /**
            * stops timer
            *
            * @param {*} timerId
            *
            * @memberOf ITimer
            */
        stop(): void;
}

export interface IWebsocketMessageFormatter {
    toConnectionMessage(message: RawWebsocketMessage): Promise<ConnectionMessage>;
    fromConnectionMessage(message: ConnectionMessage): Promise<RawWebsocketMessage>;
}

export interface IList<TItem> extends IDisposable {
    get(itemIndex: number): TItem;
    first(): TItem;
    last(): TItem;
    add(item: TItem): void;
    insertAt(index: number, item: TItem): void;
    removeFirst(): TItem;
    removeLast(): TItem;
    removeAt(index: number): TItem;
    remove(index: number, count: number): TItem[];
    clear(): void;
    length(): number;
    onAdded(addedCallback: () => void): IDetachable;
    onRemoved(removedCallback: () => void): IDetachable;
    onDisposed(disposedCallback: () => void): IDetachable;
    join(seperator?: string): string;
    toArray(): TItem[];
    any(callback?: (item: TItem, index: number) => boolean): boolean;
    all(callback: (item: TItem) => boolean): boolean;
    forEach(callback: (item: TItem, index: number) => void): void;
    select<T2>(callback: (item: TItem, index: number) => T2): List<T2>;
    where(callback: (item: TItem, index: number) => boolean): List<TItem>;
    orderBy(compareFn: (a: TItem, b: TItem) => number): List<TItem>;
    orderByDesc(compareFn: (a: TItem, b: TItem) => number): List<TItem>;
    clone(): List<TItem>;
    concat(list: List<TItem>): List<TItem>;
    concatArray(array: TItem[]): List<TItem>;
}
export class List<TItem> implements IList<TItem> {
    constructor(list?: TItem[]);
    get: (itemIndex: number) => TItem;
    first: () => TItem;
    last: () => TItem;
    add: (item: TItem) => void;
    insertAt: (index: number, item: TItem) => void;
    removeFirst: () => TItem;
    removeLast: () => TItem;
    removeAt: (index: number) => TItem;
    remove: (index: number, count: number) => TItem[];
    clear: () => void;
    length: () => number;
    onAdded: (addedCallback: () => void) => IDetachable;
    onRemoved: (removedCallback: () => void) => IDetachable;
    onDisposed: (disposedCallback: () => void) => IDetachable;
    join: (seperator?: string) => string;
    toArray: () => TItem[];
    any: (callback?: (item: TItem, index: number) => boolean) => boolean;
    all: (callback: (item: TItem) => boolean) => boolean;
    forEach: (callback: (item: TItem, index: number) => void) => void;
    select: <T2>(callback: (item: TItem, index: number) => T2) => List<T2>;
    where: (callback: (item: TItem, index: number) => boolean) => List<TItem>;
    orderBy: (compareFn: (a: TItem, b: TItem) => number) => List<TItem>;
    orderByDesc: (compareFn: (a: TItem, b: TItem) => number) => List<TItem>;
    clone: () => List<TItem>;
    concat: (list: List<TItem>) => List<TItem>;
    concatArray: (array: TItem[]) => List<TItem>;
    isDisposed: () => boolean;
    dispose: (reason?: string) => void;
}

export enum EventType {
    Debug = 0,
    Info = 1,
    Warning = 2,
    Error = 3
}
export class PlatformEvent {
    constructor(eventName: string, eventType: EventType);
    readonly name: string;
    readonly eventId: string;
    readonly eventTime: string;
    readonly eventType: EventType;
    readonly metadata: IStringDictionary<string>;
}

export enum PromiseState {
    None = 0,
    Resolved = 1,
    Rejected = 2
}
export interface IPromise<T> {
    result(): PromiseResult<T>;
    continueWith<TContinuationResult>(continuationCallback: (promiseResult: PromiseResult<T>) => TContinuationResult): IPromise<TContinuationResult>;
    continueWithPromise<TContinuationResult>(continuationCallback: (promiseResult: PromiseResult<T>) => IPromise<TContinuationResult>): IPromise<TContinuationResult>;
    onSuccessContinueWith<TContinuationResult>(continuationCallback: (result: T) => TContinuationResult): IPromise<TContinuationResult>;
    onSuccessContinueWithPromise<TContinuationResult>(continuationCallback: (result: T) => IPromise<TContinuationResult>): IPromise<TContinuationResult>;
    on(successCallback: (result: T) => void, errorCallback: (error: string) => void): IPromise<T>;
    finally(callback: () => void): IPromise<T>;
}
export interface IDeferred<T> {
    state(): PromiseState;
    promise(): IPromise<T>;
    resolve(result: T): IDeferred<T>;
    reject(error: string): IDeferred<T>;
}
export class PromiseResult<T> {
    protected privIsCompleted: boolean;
    protected privIsError: boolean;
    protected privError: string;
    protected privResult: T;
    constructor(promiseResultEventSource: PromiseResultEventSource<T>);
    readonly isCompleted: boolean;
    readonly isError: boolean;
    readonly error: string;
    readonly result: T;
    throwIfError: () => void;
}
export class PromiseResultEventSource<T> {
    setResult: (result: T) => void;
    setError: (error: string) => void;
    on: (onSetResult: (result: T) => void, onSetError: (error: string) => void) => void;
}
export class PromiseHelper {
    static whenAll: (promises: Promise<any>[]) => Promise<boolean>;
    static fromResult: <TResult>(result: TResult) => Promise<TResult>;
    static fromError: <TResult>(error: string) => Promise<TResult>;
}
export class Promise<T> implements IPromise<T> {
    constructor(sink: Sink<T>);
    result: () => PromiseResult<T>;
    continueWith: <TContinuationResult>(continuationCallback: (promiseResult: PromiseResult<T>) => TContinuationResult) => Promise<TContinuationResult>;
    onSuccessContinueWith: <TContinuationResult>(continuationCallback: (result: T) => TContinuationResult) => Promise<TContinuationResult>;
    continueWithPromise: <TContinuationResult>(continuationCallback: (promiseResult: PromiseResult<T>) => Promise<TContinuationResult>) => Promise<TContinuationResult>;
    onSuccessContinueWithPromise: <TContinuationResult>(continuationCallback: (result: T) => Promise<TContinuationResult>) => Promise<TContinuationResult>;
    on: (successCallback: (result: T) => void, errorCallback: (error: string) => void) => Promise<T>;
    finally: (callback: () => void) => Promise<T>;
}
export class Deferred<T> implements IDeferred<T> {
    constructor();
    state: () => PromiseState;
    promise: () => Promise<T>;
    resolve: (result: T) => Deferred<T>;
    reject: (error: string) => Deferred<T>;
}
export class Sink<T> {
    constructor();
    readonly state: PromiseState;
    readonly result: PromiseResult<T>;
    resolve: (result: T) => void;
    reject: (error: string) => void;
    on: (successCallback: (result: T) => void, errorCallback: (error: string) => void) => void;
}

export interface IQueue<TItem> extends IDisposable {
    enqueue(item: TItem): void;
    enqueueFromPromise(promise: Promise<TItem>): void;
    dequeue(): Promise<TItem>;
    peek(): Promise<TItem>;
    length(): number;
}
export class Queue<TItem> implements IQueue<TItem> {
    constructor(list?: List<TItem>);
    enqueue: (item: TItem) => void;
    enqueueFromPromise: (promise: Promise<TItem>) => void;
    dequeue: () => Promise<TItem>;
    peek: () => Promise<TItem>;
    length: () => number;
    isDisposed: () => boolean;
    drainAndDispose: (pendingItemProcessor: (pendingItemInQueue: TItem) => void, reason?: string) => Promise<boolean>;
    dispose: (reason?: string) => void;
}

export class RawWebsocketMessage {
    constructor(messageType: MessageType, payload: any, id?: string);
    readonly messageType: MessageType;
    readonly payload: any;
    readonly textContent: string;
    readonly binaryContent: ArrayBuffer;
    readonly id: string;
}

export class RiffPcmEncoder {
    constructor(actualSampleRate: number, desiredSampleRate: number);
    encode: (needHeader: boolean, actualAudioFrame: Float32Array) => ArrayBuffer;
}

export interface IStreamChunk<TBuffer> {
    isEnd: boolean;
    buffer: TBuffer;
    timeReceived: number;
}
export class Stream<TBuffer> {
    constructor(streamId?: string);
    readonly isClosed: boolean;
    readonly id: string;
    getReader: () => StreamReader<TBuffer>;
    close(): void;
    writeStreamChunk(streamChunk: IStreamChunk<TBuffer>): void;
}
export class StreamReader<TBuffer> {
    constructor(streamId: string, readerQueue: Queue<IStreamChunk<TBuffer>>, onClose: () => void);
    readonly isClosed: boolean;
    readonly streamId: string;
    read: () => Promise<IStreamChunk<TBuffer>>;
    close: () => void;
}

/**
    * Defines translation status.
    * @class TranslationStatus
    */
export enum TranslationStatus {
        /**
            * @member TranslationStatus.Success
            */
        Success = 0,
        /**
            * @member TranslationStatus.Error
            */
        Error = 1
}

export class ChunkedArrayBufferStream extends Stream<ArrayBuffer> {
    constructor(targetChunkSize: number, streamId?: string);
    writeStreamChunk(chunk: IStreamChunk<ArrayBuffer>): void;
    close(): void;
}

export abstract class ConnectionFactoryBase implements IConnectionFactory {
    abstract create(config: RecognizerConfig, authInfo: AuthInfo, connectionId?: string): IConnection;
    protected setCommonUrlParams(config: RecognizerConfig, queryParams: IStringDictionary<string>, endpoint: string): void;
    protected setUrlParameter(propId: PropertyId, parameterName: string, config: RecognizerConfig, queryParams: IStringDictionary<string>, endpoint: string): void;
}

export class SpeechConnectionMessage extends ConnectionMessage {
    constructor(messageType: MessageType, path: string, requestId: string, contentType: string, body: any, additionalHeaders?: IStringDictionary<string>, id?: string);
    readonly path: string;
    readonly requestId: string;
    readonly contentType: string;
    readonly additionalHeaders: IStringDictionary<string>;
    static fromConnectionMessage: (message: ConnectionMessage) => SpeechConnectionMessage;
}

export class ConsoleLoggingListener implements IEventListener<PlatformEvent> {
    constructor(logLevelFilter?: EventType);
    onEvent: (event: PlatformEvent) => void;
}

export interface IRecorder {
    record(context: AudioContext, mediaStream: MediaStream, outputStream: Stream<ArrayBuffer>): void;
    releaseMediaResources(context: AudioContext): void;
    setWorkletUrl(url: string): void;
}

export const AudioWorkletSourceURLPropertyName = "MICROPHONE-WorkletSourceUrl";
export class MicAudioSource implements IAudioSource {
    constructor(privRecorder: IRecorder, outputChunkSize: number, audioSourceId?: string, deviceId?: string);
    readonly format: AudioStreamFormat;
    turnOn: () => Promise<boolean>;
    id: () => string;
    attach: (audioNodeId: string) => Promise<IAudioStreamNode>;
    detach: (audioNodeId: string) => void;
    turnOff: () => Promise<boolean>;
    readonly events: EventSource<AudioSourceEvent>;
    readonly deviceInfo: Promise<ISpeechConfigAudioDevice>;
    setProperty(name: string, value: string): void;
}

export class FileAudioSource implements IAudioSource {
    constructor(file: File, audioSourceId?: string);
    readonly format: AudioStreamFormat;
    turnOn: () => Promise<boolean>;
    id: () => string;
    attach: (audioNodeId: string) => Promise<IAudioStreamNode>;
    detach: (audioNodeId: string) => void;
    turnOff: () => Promise<boolean>;
    readonly events: EventSource<AudioSourceEvent>;
    readonly deviceInfo: Promise<ISpeechConfigAudioDevice>;
}

export class PcmRecorder implements IRecorder {
    record: (context: AudioContext, mediaStream: MediaStream, outputStream: Stream<ArrayBuffer>) => void;
    releaseMediaResources: (context: AudioContext) => void;
    setWorkletUrl(url: string): void;
}

export class WebsocketConnection implements IConnection {
    constructor(uri: string, queryParameters: IStringDictionary<string>, headers: IStringDictionary<string>, messageFormatter: IWebsocketMessageFormatter, proxyInfo: ProxyInfo, connectionId?: string);
    dispose: () => void;
    isDisposed: () => boolean;
    readonly id: string;
    state: () => ConnectionState;
    open: () => Promise<ConnectionOpenResponse>;
    send: (message: ConnectionMessage) => Promise<boolean>;
    read: () => Promise<ConnectionMessage>;
    readonly events: EventSource<ConnectionEvent>;
}

export class WebsocketMessageAdapter {
    static forceNpmWebSocket: boolean;
    constructor(uri: string, connectionId: string, messageFormatter: IWebsocketMessageFormatter, proxyInfo: ProxyInfo, headers: {
        [key: string]: string;
    });
    readonly state: ConnectionState;
    open: () => Promise<ConnectionOpenResponse>;
    send: (message: ConnectionMessage) => Promise<boolean>;
    read: () => Promise<ConnectionMessage>;
    close: (reason?: string) => Promise<boolean>;
    readonly events: EventSource<ConnectionEvent>;
}

export class ReplayableAudioNode implements IAudioStreamNode {
    constructor(audioSource: IAudioStreamNode, format: AudioStreamFormatImpl);
    id: () => string;
    read(): Promise<IStreamChunk<ArrayBuffer>>;
    detach(): void;
    replay(): void;
    shrinkBuffers(offset: number): void;
    findTimeAtOffset(offset: number): number;
}

export class ProxyInfo {
    static fromRecognizerConfig(config: RecognizerConfig): ProxyInfo;
    readonly HostName: string;
    readonly Port: number;
    readonly UserName: string;
    readonly Password: string;
}

